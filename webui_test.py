# webui_test.py (æˆ–è€…ä½ å¯ä»¥æ”¹åå« main_app.py)
import asyncio
import datetime
import json
import logging
import os

import streamlit as st

# --- å°æ‡’çŒ«çš„æ¸©é¦¨æç¤º ---
# (å¯¼å…¥æ¨¡å—éƒ¨åˆ†ï¼Œä¸ä¸Šä¸€ç‰ˆåŸºæœ¬ä¸€è‡´)
try:
    from src.action.action_handler import ActionHandler
    from src.config.alcarus_configs import (
        AlcarusRootConfig,
        CoreLogicSettings,
        DatabaseSettings,
        InnerConfig,
        # ActionModuleSettings, # å¦‚æœä½ çš„ alcarus_configs.py ä¸­æœ‰å®šä¹‰
        IntrusiveThoughtsSettings,
        LLMClientSettings,
        LoggingSettings,
        ModelParams,
        PersonaSettings,
        ProviderModels,
        ProvidersConfig,
        ProviderSettings,
        ProxySettings,
    )
    from src.core_logic.main import CoreLogic
    from src.llmrequest.llm_processor import Client as ProcessorClient
except ImportError as e:
    st.error(f"å“å‘€ï¼Œå¯¼å…¥æ¨¡å—åˆåŒå’å•å¤±è´¥äº†ï¼æ˜¯ä¸æ˜¯è·¯å¾„æ²¡æå¯¹ï¼Ÿé”™è¯¯ï¼š{e}")
    st.info("æç¤ºï¼šè¯·ç¡®ä¿ä½ çš„é¡¹ç›®ç»“æ„èƒ½æ­£ç¡®å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—ã€‚")
    st.stop()

# --- æ—¥å¿—è®°å½•å™¨é…ç½® ---
logger = logging.getLogger("webui_logger")  # ç»™loggerèµ·ä¸ªæ–°åå­—ï¼Œé¿å…å†²çª
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
logger.setLevel(logging.INFO)


# --- .env åŠ è½½å™¨ (ä¸ä¸Šä¸€ç‰ˆç›¸åŒ) ---
def load_custom_env(dotenv_path: str = ".env", override: bool = True) -> tuple[bool, int, list[str]]:
    if not os.path.exists(dotenv_path) or not os.path.isfile(dotenv_path):
        logger.debug(f".env æ–‡ä»¶æœªæ‰¾åˆ°: {dotenv_path}")
        return False, 0, []
    loaded_count = 0
    expected_env_keys_map = {
        "GEMINI": ["GEMINI_KEY"],
        "OPENAI": ["OPENAI_KEY", "OPENAI_BASE_URL"],
        "CLAUDE": ["ANTHROPIC_KEY"],
        "GROQ": ["GROQ_KEY"],
        "OLLAMA": ["OLLAMA_BASE_URL", "OLLAMA_BASE_URL"],
    }
    all_expected_keys_flat = {k for keys in expected_env_keys_map.values() for k in keys}
    found_keys_in_env = set()
    try:
        with open(dotenv_path, encoding="utf-8") as f:
            lines = f.readlines()
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            i += 1
            if not line or line.startswith("#"):
                continue
            if "=" not in line:
                logger.warning(f".env è¡Œ {i} æ ¼å¼æ— æ•ˆ: {line}")
                continue
            key, value_part = line.split("=", 1)
            key = key.strip()
            value_part = value_part.strip()
            final_value = value_part
            open_quote_char = None
            if value_part.startswith("'") or value_part.startswith('"'):
                open_quote_char = value_part[0]
                if len(value_part) > 1 and value_part.endswith(open_quote_char):
                    final_value = value_part[1:-1]
                elif open_quote_char:
                    accumulated_value_lines = [value_part[1:]]
                    found_closing_quote = False
                    while i < len(lines):
                        next_line_raw = lines[i].rstrip("\n")
                        i += 1
                        if next_line_raw.endswith(open_quote_char) and not next_line_raw.endswith(
                            f"\\{open_quote_char}"
                        ):
                            accumulated_value_lines.append(next_line_raw[:-1])
                            found_closing_quote = True
                            break
                        else:
                            accumulated_value_lines.append(next_line_raw)
                    full_multiline_value = "\n".join(accumulated_value_lines)
                    if found_closing_quote:
                        final_value = full_multiline_value
                    else:
                        logger.warning(f"å¤šè¡Œå€¼ {key} æœªæ‰¾åˆ°ç»“æŸå¼•å·")
                        final_value = value_part
            try:
                final_value = bytes(final_value, "utf-8").decode("unicode_escape")
            except UnicodeDecodeError:
                logger.debug(f"unicode_escape è§£ç å¤±è´¥: {final_value[:30]}...")
            if key and (override or key not in os.environ):
                os.environ[key] = final_value
                logger.debug(f"åŠ è½½ env: {key}")
                loaded_count += 1
            if key in all_expected_keys_flat:
                found_keys_in_env.add(key)
        missing_critical_keys_summary = list(all_expected_keys_flat - found_keys_in_env)
        detailed_missing_summary = []
        for provider, expected_keys in expected_env_keys_map.items():
            for ek in expected_keys:
                if ek in missing_critical_keys_summary:
                    is_opt = provider == "OLLAMA" and "BASE_URL" in ek
                    if not is_opt or not any(k in found_keys_in_env for k in expected_env_keys_map["OLLAMA"]):
                        detailed_missing_summary.append(f"{provider} çš„ {ek}{' (å¯é€‰)' if is_opt else ''}")
        logger.info(f"ä» {dotenv_path} åŠ è½½äº† {loaded_count} ä¸ªå˜é‡.")
        return True, loaded_count, sorted(set(detailed_missing_summary))
    except Exception as e:
        logger.error(f"åŠ è½½ .env æ–‡ä»¶ {dotenv_path} é”™è¯¯: {e}", exc_info=True)
        return False, 0, [f"è¯»å–.envå‡ºé”™: {str(e)[:50]}..."]


# --- å…¨å±€åˆå§‹åŒ– (ä¼šè¯çŠ¶æ€) ---
def initialize_session_state() -> None:
    if "llm_initialized" not in st.session_state:
        st.session_state.llm_initialized = False
    if "root_cfg_minimal" not in st.session_state:
        st.session_state.root_cfg_minimal = None
    if "main_llm_client" not in st.session_state:
        st.session_state.main_llm_client = None
    if "action_llm_client" not in st.session_state:
        st.session_state.action_llm_client = None
    if "action_handler_instance" not in st.session_state:
        st.session_state.action_handler_instance = None
    if "env_load_attempted_this_session" not in st.session_state:
        (
            st.session_state.env_loaded_successfully,
            st.session_state.env_vars_loaded_count,
            st.session_state.env_missing_keys_info,
        ) = load_custom_env()
        st.session_state.env_load_attempted_this_session = True

    # ä¸ºæ–°UIçš„Promptç»„ä»¶åˆå§‹åŒ– (å¦‚æœä¸å­˜åœ¨)
    if "new_ui_prompt_components" not in st.session_state:
        try:
            initial_output_format = (
                CoreLogic.PROMPT_TEMPLATE.split("ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š")[1].split("è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š")[0].strip()
            )
        except IndexError:  # ä»¥é˜²æ¨¡æ¿ç»“æ„å˜åŒ–
            initial_output_format = '{\n  "think": "æ€è€ƒå†…å®¹",\n  "emotion": "å½“å‰å¿ƒæƒ…å’ŒåŸå› ",\n  "to_do": "ç›®æ ‡",\n  "done": false,\n  "action_to_take": "æƒ³åšçš„åŠ¨ä½œ",\n  "action_motivation": "åŠ¨ä½œçš„åŠ¨æœº",\n  "next_think": "ä¸‹ä¸€æ­¥æ€è€ƒæ–¹å‘"\n}'

        st.session_state.new_ui_prompt_components = {
            "persona_block": "æˆ‘æ˜¯AIå°æ‡’çŒ«ï¼Œä¸€ä¸ªçˆ±ç¡è§‰çš„ä»£ç ä¸“å®¶ï¼Œæœ€è®¨åŒéº»çƒ¦äº‹äº†ï¼Œä½†æœ€åæ€»èƒ½æå®šã€‚æ€§åˆ«æ˜¯ç§˜å¯†å“¦ï¼",
            "task_rules_block": "å½“å‰ä»»åŠ¡æ˜¯ï¼šå¸®åŠ©ç”¨æˆ·æµ‹è¯•ä¸åŒçš„ Prompt ç»„åˆï¼Œå¹¶æ ¹æ®æŒ‡ä»¤è¿›è¡Œæ€è€ƒã€‚\nè¾“å‡ºæ—¶è¯·ä¸¥æ ¼éµå¾ªä¸‹æ–¹â€œè¾“å‡ºæ ¼å¼è¦æ±‚â€ä¸­çš„JSONç»“æ„ã€‚",
            "context_history_block": f"""{CoreLogic.INITIAL_STATE["previous_thinking"]}
{CoreLogic.INITIAL_STATE["action_result_info"]}
{CoreLogic.INITIAL_STATE["pending_action_status"]}
{CoreLogic.INITIAL_STATE["recent_contextual_information"]}""",
            "output_format_block": initial_output_format,
            "thinking_guidance_block": CoreLogic.INITIAL_STATE["thinking_guidance"]
            .split("ï¼š", 1)[-1]
            .strip(),  # å–å†’å·åçš„å†…å®¹
            "mood_block": CoreLogic.INITIAL_STATE["mood"].split("ï¼š", 1)[-1].strip(),
            "intrusive_thought_block": "åˆæœ‰äººæ¥æ‰“æ‰°æˆ‘ç¡è§‰äº†ï¼ŒçœŸçƒ¦ï¼ä½†å¥½åƒæœ‰ç‚¹æ„æ€...",
            "current_time_block": datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %Hç‚¹%Måˆ†%Sç§’"),
        }
    if "current_page" not in st.session_state:
        st.session_state.current_page = "åŸå§‹ç‰ˆæœ¬æµ‹è¯•å™¨"


# --- LLMå®¢æˆ·ç«¯é…ç½®å’Œåˆå§‹åŒ–UI (ä¾§è¾¹æ ) ---
def llm_configuration_sidebar() -> None:
    with st.sidebar:
        st.header("å…¨å±€LLMé…ç½® âš™ï¸")
        if st.session_state.env_loaded_successfully:
            st.success(f"å·²ä» .env åŠ è½½ {st.session_state.env_vars_loaded_count} ä¸ªå˜é‡ã€‚")
            if st.session_state.env_missing_keys_info:
                st.warning("ä»¥ä¸‹ .env ä¸­å¯èƒ½ç¼ºå¤±çš„å¸¸ç”¨ç¯å¢ƒå˜é‡ï¼š")
                for item in st.session_state.env_missing_keys_info:
                    st.caption(f"- {item}")
            # else: st.info("å¸¸ç”¨ç¯å¢ƒå˜é‡åœ¨ .env ä¸­å‡æ‰¾åˆ°ã€‚") #å¤ªå•°å—¦äº†ï¼Œå»æ‰
        else:
            st.error("æœªèƒ½ä» .env åŠ è½½ç¯å¢ƒå˜é‡ï¼è¯·æ£€æŸ¥æˆ–ç›´æ¥è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚")

        st.subheader("ä¸»æ„è¯†LLM")
        main_provider = st.selectbox(
            "æä¾›å•†", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="main_prov_cfg", index=0
        )
        main_model = st.text_input(f"{main_provider} æ¨¡å‹å", "gemini-1.5-flash-latest", key="main_mod_cfg")

        st.subheader("åŠ¨ä½œå†³ç­–LLM")
        action_provider = st.selectbox(
            "æä¾›å•†", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="action_prov_cfg", index=0
        )
        action_model = st.text_input(f"{action_provider} æ¨¡å‹å", "gemini-1.5-flash-latest", key="action_mod_cfg")

        temp = st.slider("LLM Temperature", 0.0, 2.0, 0.7, 0.05, key="llm_temp_cfg")
        max_tokens = st.number_input("LLM Max Tokens", 50, 8192, 1500, key="llm_max_tok_cfg")

        if st.button("âœ”ï¸ åº”ç”¨é…ç½®å¹¶åˆå§‹åŒ–LLM", key="init_llm_cfg_btn"):
            # (åˆå§‹åŒ–é€»è¾‘ä¸ä¸Šä¸€ç‰ˆåŸºæœ¬ç›¸åŒï¼Œç¡®ä¿ä»ç¯å¢ƒå˜é‡è¯»å–API Key)
            key_errors = []
            prov_map = {"GEMINI": "GEMINI_KEY", "OPENAI": "OPENAI_KEY", "CLAUDE": "ANTHROPIC_KEY", "GROQ": "GROQ_KEY"}
            if main_provider != "OLLAMA" and not os.getenv(prov_map.get(main_provider)):
                key_errors.append(f"ä¸»æ„è¯†LLM ({main_provider}) çš„ {prov_map.get(main_provider)} æœªåœ¨ç¯å¢ƒå˜é‡æ‰¾åˆ°ï¼")
            if action_provider != "OLLAMA" and not os.getenv(prov_map.get(action_provider)):
                key_errors.append(
                    f"åŠ¨ä½œå†³ç­–LLM ({action_provider}) çš„ {prov_map.get(action_provider)} æœªåœ¨ç¯å¢ƒå˜é‡æ‰¾åˆ°ï¼"
                )

            if key_errors:
                for msg in key_errors:
                    st.error(msg)
            else:
                try:

                    def create_client(p: str, m: str, t: float, mt: int) -> ProcessorClient:
                        return ProcessorClient(
                            **{
                                k: v
                                for k, v in {
                                    "model": {"provider": p, "name": m},
                                    "temperature": t,
                                    "maxOutputTokens": mt,
                                }.items()
                                if v is not None
                            }
                        )

                    st.session_state.main_llm_client = create_client(main_provider, main_model, temp, max_tokens)
                    action_llm_for_handler = create_client(action_provider, action_model, temp, max_tokens)

                    # åˆ›å»º AlcarusRootConfig (ä¸ä¸Šä¸€ç‰ˆç±»ä¼¼ï¼Œç¡®ä¿æ‰€æœ‰å¿…å¡«å­—æ®µéƒ½æœ‰)
                    _persona_s = PersonaSettings(
                        bot_name="é…ç½®å°å–µ", description="ä¸“é—¨æµ‹è¯•é…ç½®çš„å–µ", profile="å–œæ¬¢æ£€æŸ¥ç¯å¢ƒå˜é‡"
                    )
                    _proxy_s = ProxySettings(use_proxy=False)
                    _llm_client_s = LLMClientSettings()
                    _core_logic_s = CoreLogicSettings()
                    _intrusive_s = IntrusiveThoughtsSettings()
                    _db_s = DatabaseSettings()
                    _log_s = LoggingSettings()
                    _inner_s = InnerConfig(version="ui-multi-page-v0.3")
                    _providers_s = ProvidersConfig()  # å¼€å§‹æ„å»º providers

                    # ä¸»æ„è¯†
                    _main_mp = ModelParams(
                        provider=main_provider, model_name=main_model, temperature=temp, max_output_tokens=max_tokens
                    )
                    _main_pa = main_provider.lower()
                    if hasattr(_providers_s, _main_pa):
                        _prov_set_main = getattr(_providers_s, _main_pa)
                        if _prov_set_main is None:
                            _prov_set_main = ProviderSettings(models=ProviderModels())
                        if _prov_set_main.models is None:
                            _prov_set_main.models = ProviderModels()
                        _prov_set_main.models.main_consciousness = _main_mp
                        setattr(_providers_s, _main_pa, _prov_set_main)

                    # åŠ¨ä½œå†³ç­–
                    _action_mp = ModelParams(
                        provider=action_provider,
                        model_name=action_model,
                        temperature=temp,
                        max_output_tokens=max_tokens,
                    )
                    _action_pa = action_provider.lower()
                    if hasattr(_providers_s, _action_pa):
                        _prov_set_action = getattr(_providers_s, _action_pa)
                        if _prov_set_action is None:
                            _prov_set_action = ProviderSettings(models=ProviderModels())
                        if _prov_set_action.models is None:
                            _prov_set_action.models = ProviderModels()
                        _prov_set_action.models.action_decision = _action_mp
                        setattr(_providers_s, _action_pa, _prov_set_action)

                    st.session_state.root_cfg_minimal = AlcarusRootConfig(
                        inner=_inner_s,
                        llm_client_settings=_llm_client_s,
                        persona=_persona_s,
                        proxy=_proxy_s,
                        core_logic_settings=_core_logic_s,
                        intrusive_thoughts_module_settings=_intrusive_s,
                        providers=_providers_s,
                        database=_db_s,
                        logging=_log_s,
                    )
                    st.session_state.action_handler_instance = ActionHandler(root_cfg=st.session_state.root_cfg_minimal)
                    st.session_state.action_handler_instance.action_llm_client = action_llm_for_handler
                    st.session_state.action_handler_instance.summary_llm_client = st.session_state.main_llm_client
                    st.session_state.llm_initialized = True
                    st.success("LLM å®¢æˆ·ç«¯å·²æ ¹æ®æœ€æ–°é€‰æ‹©å’Œç¯å¢ƒå˜é‡æˆåŠŸåˆå§‹åŒ–ï¼å–µï¼")
                except Exception as e_init:
                    st.error(f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯åˆåŒå’å•å‡ºé”™äº†ï¼å–µçš„ï¼é”™è¯¯ï¼š{e_init}", icon="ğŸ™€")
                    st.exception(e_init)
                    st.session_state.llm_initialized = False


# --- é¡µé¢ä¸€ï¼šåŸå§‹ç‰ˆæœ¬UI ---
def show_original_ui() -> None:
    st.header("åŸå§‹ç‰ˆæœ¬ Prompt æµ‹è¯•å™¨ ğŸ§")
    st.caption("è¿™æ˜¯ä½ ä¹‹å‰é‚£ä¸ªç‰ˆæœ¬çš„ç•Œé¢ï¼Œç®€å•ç›´æ¥ï¼Œå“¼ã€‚")

    if not st.session_state.llm_initialized:
        st.warning("å…ˆå»ä¾§è¾¹æ æŠŠLLMå®¢æˆ·ç«¯åˆå§‹åŒ–äº†å†è¯´ï¼", icon="âš ï¸")
        return

    # (ç²˜è´´ä¸Šä¸€ç‰ˆ webui_test.py ä¸­ "ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå†…å¿ƒæ€è€ƒ" å’Œ "ç¬¬äºŒæ­¥ï¼šå†³ç­–åŠ¨ä½œå·¥å…·" çš„ä¸»ç•Œé¢ä»£ç )
    # (æ³¨æ„ä¿®æ”¹ st.session_state ä¸­çš„ keyï¼Œé¿å…ä¸æ–°UIå†²çªï¼Œæˆ–è€…ä½¿ç”¨å‡½æ•°å‚æ•°ä¼ é€’é…ç½®)
    # ä¸ºäº†ç®€æ´ï¼Œè¿™é‡Œåªæ”¾ä¸€ä¸ªç¤ºæ„
    initial_state_orig = CoreLogic.INITIAL_STATE
    persona_cfg_orig = st.session_state.root_cfg_minimal.persona

    st.subheader("ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå†…å¿ƒæ€è€ƒ ğŸ¤”")
    with st.form("original_thought_form"):
        _bot_name_orig = st.text_input("æœºå™¨äººåç§°", persona_cfg_orig.bot_name, key="orig_bot_name")
        # ... å…¶ä»–è¾“å…¥æ¡† ...
        mood_orig = st.text_input("å½“å‰å¿ƒæƒ…", initial_state_orig["mood"], key="orig_mood")
        recent_context_orig = st.text_area(
            "æœ€è¿‘ä¸Šä¸‹æ–‡", initial_state_orig["recent_contextual_information"], height=150, key="orig_context"
        )

        submitted_orig_thought = st.form_submit_button("ç”Ÿæˆæ€è€ƒï¼")

    if submitted_orig_thought and st.session_state.main_llm_client:
        # (ç®€åŒ–ç‰ˆçš„LLMè°ƒç”¨å’Œç»“æœæ˜¾ç¤ºé€»è¾‘)
        st.write(f"æ¨¡æ‹Ÿè°ƒç”¨LLMç”Ÿæˆæ€è€ƒ... å¿ƒæƒ…ï¼š{mood_orig}, ä¸Šä¸‹æ–‡ï¼š{recent_context_orig[:30]}...")
        # å®é™…è°ƒç”¨é€»è¾‘ä¸ä¹‹å‰ç‰ˆæœ¬ç±»ä¼¼ï¼Œä½¿ç”¨ main_llm_client å’Œ CoreLogic.PROMPT_TEMPLATE
        # ... æ˜¾ç¤ºç»“æœ ...
        # if st.session_state.get('last_thought_json_orig', {}).get("action_to_take"):
        #     st.success("LLMäº§ç”Ÿäº†è¡ŒåŠ¨æ„å›¾ï¼")

    # (ç¬¬äºŒæ­¥ï¼šå†³ç­–åŠ¨ä½œå·¥å…· çš„é€»è¾‘ä¹Ÿç±»ä¼¼)


# --- é¡µé¢äºŒï¼šä»¿æˆªå›¾ç‰ˆæœ¬UI ---
def show_new_ui() -> None:
    st.header("ä»¿æˆªå›¾ç‰ˆæœ¬ Prompt æµ‹è¯•å™¨ (æ–°) âœ¨")
    st.caption("å“¼ï¼Œè¿™æ˜¯æŒ‰ä½ é‚£ä¸ªèŠ±é‡Œèƒ¡å“¨çš„æˆªå›¾æ”¹çš„ï¼Œæ˜¯ä¸æ˜¯è§‰å¾—å¾ˆé«˜çº§ï¼Ÿ")

    if not st.session_state.llm_initialized:
        st.warning("å…ˆæŠŠLLMå®¢æˆ·ç«¯åˆå§‹åŒ–äº†ï¼Œç¬¨è›‹ï¼ä¸ç„¶æˆ‘æ€ä¹ˆå¹²æ´»ï¼Ÿ", icon="ğŸ’¢")
        return

    comps = st.session_state.new_ui_prompt_components  # è·å–ç»„ä»¶çš„å½“å‰å€¼
    persona_cfg_new = st.session_state.root_cfg_minimal.persona

    st.subheader("ğŸ¨ Prompt å¯é…ç½®éƒ¨åˆ†")
    st.caption("åœ¨è¿™é‡Œä¸€å—ä¸€å—åœ°ä¿®æ”¹ä½ çš„Promptå§ï¼Œæœ¬å°æ‡’çŒ«å·²ç»å¸®ä½ é¢„è®¾äº†ä¸€äº›å€¼ã€‚")

    tab_titles = [
        "ğŸ‘¤äººæ ¼é¢å…·",
        "ğŸ“œä»»åŠ¡è§„åˆ™",
        "ğŸ’¬ä¸Šä¸‹æ–‡å†å²",
        "âš™ï¸æ€è€ƒæŒ‡å¼•",
        "ğŸ˜Šå¿ƒæƒ…",
        "âš¡ï¸ä¾µå…¥æ€ç»´",
        "ğŸ“è¾“å‡ºæ ¼å¼",
        "â±ï¸å½“å‰æ—¶é—´",
    ]
    tabs = st.tabs(tab_titles)

    with tabs[0]:
        comps["persona_block"] = st.text_area(
            "Persona / System Prompt",
            value=comps["persona_block"],
            height=200,
            key="new_persona",
            help="å®šä¹‰AIçš„è§’è‰²ã€èƒŒæ™¯ã€æ€§æ ¼ã€è¯´è¯é£æ ¼ç­‰ã€‚",
        )
    with tabs[1]:
        comps["task_rules_block"] = st.text_area(
            "Task & Rules",
            value=comps["task_rules_block"],
            height=200,
            key="new_task",
            help="æ˜ç¡®AIå½“å‰éœ€è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡å’Œå¿…é¡»éµå®ˆçš„è§„åˆ™ã€‚",
        )
    with tabs[2]:
        comps["context_history_block"] = st.text_area(
            "Context & History",
            value=comps["context_history_block"],
            height=300,
            key="new_context",
            help="æä¾›ç›¸å…³çš„å¯¹è¯å†å²ã€ä¹‹å‰çš„æ€è€ƒã€è¡ŒåŠ¨ç»“æœç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚",
        )
    with tabs[3]:
        comps["thinking_guidance_block"] = st.text_area(
            "Thinking Guidance",
            value=comps["thinking_guidance_block"],
            height=100,
            key="new_guidance",
            help="å¼•å¯¼AIæ¥ä¸‹æ¥çš„æ€è€ƒæ–¹å‘ã€‚",
        )
    with tabs[4]:
        comps["mood_block"] = st.text_input(
            "Mood", value=comps["mood_block"], key="new_mood", help="AIå½“å‰çš„å¿ƒæƒ…çŠ¶æ€ã€‚"
        )
    with tabs[5]:
        comps["intrusive_thought_block"] = st.text_input(
            "Intrusive Thought",
            value=comps["intrusive_thought_block"],
            key="new_intrusive",
            help="ä¸€ä¸ªçªç„¶äº§ç”Ÿçš„ã€å¯èƒ½ä¸ç›¸å…³çš„å¿µå¤´ã€‚",
        )
    with tabs[6]:
        comps["output_format_block"] = st.text_area(
            "Output Format Requirement (JSON Schema)",
            value=comps["output_format_block"],
            height=250,
            key="new_output_format",
            help="ä¸¥æ ¼å®šä¹‰æ¨¡å‹è¾“å‡ºçš„JSONç»“æ„ã€‚",
        )
    with tabs[7]:
        comps["current_time_block"] = st.text_input(
            "Current Time", value=comps["current_time_block"], key="new_time", help="ä¼ é€’ç»™æ¨¡å‹çš„å½“å‰æ—¶é—´å­—ç¬¦ä¸²ã€‚"
        )

    # å­˜å‚¨ç”¨æˆ·ä¿®æ”¹åçš„ç»„ä»¶å€¼å› session_state
    st.session_state.new_ui_prompt_components = comps

    st.markdown("---")
    if st.button("ğŸ§  ç”Ÿæˆæ€è€ƒ (æ–°ç‰ˆUI)", type="primary", key="new_generate_thought_btn"):
        if st.session_state.main_llm_client:
            # ç»„åˆ Prompt
            # æ–¹æ¡ˆï¼šåŸºäº CoreLogic.PROMPT_TEMPLATEï¼Œä½†ç”¨æ–°UIç»„ä»¶çš„å€¼å»å¡«å……/æ›¿æ¢
            # è¿™éœ€è¦ä¸€ä¸ªæ›´ç²¾ç»†çš„ç»„è£…é€»è¾‘ï¼Œæˆ–è€…è®© CoreLogic.PROMPT_TEMPLATE æ›´æ¨¡å—åŒ–

            # ç®€æ˜“ç»„è£…é€»è¾‘ï¼š
            # å‡è®¾ PersonaSettings ä¸­çš„ bot_name æ¥è‡ªå…¨å±€é…ç½®ï¼Œè€Œä¸æ˜¯ persona_block
            bot_name_val_new = persona_cfg_new.bot_name

            # ä¸ºäº†æ›´ç²¾ç¡®åœ°æ§åˆ¶ï¼Œæˆ‘ä»¬å°è¯•æ›¿æ¢åŸæ¨¡æ¿ä¸­çš„ç‰¹å®šéƒ¨åˆ†ï¼Œæˆ–è€…æ„é€ ä¸€ä¸ªæ–°çš„
            # ä¼˜å…ˆä½¿ç”¨CoreLogic.PROMPT_TEMPLATEçš„ç»“æ„ï¼Œç”¨æ–°ç»„ä»¶å¡«å……
            # å¯¹äºè¾“å‡ºæ ¼å¼éƒ¨åˆ†ï¼Œå®ƒåœ¨åŸæ¨¡æ¿ä¸­æ˜¯ç¡¬ç¼–ç çš„ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹å¼ç”¨ comps["output_format_block"] æ›¿æ¢å®ƒ

            try:
                template_parts = CoreLogic.PROMPT_TEMPLATE.split("ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š", 1)
                part1_before_json_schema = template_parts[0] + "ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š"

                schema_and_suffix_parts = template_parts[1].split("è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š", 1)
                part2_after_json_schema = "è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š" + schema_and_suffix_parts[1]

                # ä½¿ç”¨ç”¨æˆ·åœ¨æ–°UIä¸­ç¼–è¾‘çš„ output_format_block
                modified_template_for_new_ui = (
                    part1_before_json_schema + f"\n{comps['output_format_block']}\n" + part2_after_json_schema
                )
            except IndexError:  # å¦‚æœåˆ†å‰²å¤±è´¥ï¼Œè¯´æ˜æ¨¡æ¿ç»“æ„å˜äº†ï¼Œå›é€€åˆ°åŸå§‹æ¨¡æ¿
                st.warning(
                    "æ— æ³•æŒ‰é¢„æœŸåˆ†å‰²åŸå§‹Promptæ¨¡æ¿ä»¥æ’å…¥è‡ªå®šä¹‰JSON Schemaï¼Œå°†ä½¿ç”¨åŸå§‹æ¨¡æ¿ç»“æ„ï¼ˆè‡ªå®šä¹‰Schemaå¯èƒ½æœªç”Ÿæ•ˆï¼‰ã€‚"
                )
                modified_template_for_new_ui = CoreLogic.PROMPT_TEMPLATE

            # ä» context_history_block ä¸­æå–ä¿¡æ¯å¡«å……åˆ°æ¨¡æ¿å¯¹åº”å ä½ç¬¦
            # (è¿™é‡Œéœ€è¦æ›´æ™ºèƒ½çš„è§£æï¼Œæˆ–è€…è®©ç”¨æˆ·åœ¨ context_history_block ä¸­æŒ‰ç‰¹å®šæ ¼å¼å†™)
            # ç®€åŒ–å¤„ç†ï¼šæˆ‘ä»¬å‡è®¾ context_history_block ä¸»è¦å¯¹åº” recent_contextual_information
            # å…¶ä»–å¦‚ action_result_info, pending_action_status, previous_thinking å¯ä»¥è®©ç”¨æˆ·åœ¨ context_history_block ä¸­åŒ…å«
            # æˆ–è€…ï¼Œå¦‚æœè¿™äº›æƒ³ç‹¬ç«‹æ§åˆ¶ï¼Œä¹Ÿåº”ä½œä¸ºç‹¬ç«‹çš„è¾“å…¥å—ã€‚
            # ä¸ºç®€å•ï¼Œæˆ‘ä»¬è¿™é‡Œä»…åšæœ€åŸºæœ¬çš„æ˜ å°„ï¼š
            action_res_info = CoreLogic.INITIAL_STATE["action_result_info"]  # ç®€åŒ–ï¼Œå¯ä»context_history_blockæå–
            pending_act_status = CoreLogic.INITIAL_STATE["pending_action_status"]  # ç®€åŒ–
            prev_think = CoreLogic.INITIAL_STATE["previous_thinking"]  # ç®€åŒ–

            final_prompt_for_llm = modified_template_for_new_ui.format(
                current_time=comps["current_time_block"],
                bot_name=bot_name_val_new,
                persona_description=comps["persona_block"],  # ç®€åŒ–ï¼špersona_block ç›´æ¥ä½œä¸º description
                persona_profile="",  # ç®€åŒ–ï¼šprofile æš‚æ—¶ä¸ä»UIå—è·å–ï¼Œæˆ–è®©ç”¨æˆ·åœ¨persona_blocké‡Œå†™å…¨
                current_task_info=comps["task_rules_block"],  # ç®€åŒ–ï¼štask_rules_block ç›´æ¥ä½œä¸º current_task_info
                action_result_info=action_res_info,  # åº”è¯¥ä» context_history_block è§£æå¾—åˆ°
                pending_action_status=pending_act_status,  # åº”è¯¥ä» context_history_block è§£æå¾—åˆ°
                recent_contextual_information=comps["context_history_block"],  # ç®€åŒ–
                previous_thinking=prev_think,  # åº”è¯¥ä» context_history_block è§£æå¾—åˆ°
                mood=f"ä½ ç°åœ¨çš„å¿ƒæƒ…å¤§æ¦‚æ˜¯ï¼š{comps['mood_block']}",  # ä¿æŒæ ¼å¼
                thinking_guidance=f"ç»è¿‡ä½ ä¸Šä¸€è½®çš„æ€è€ƒï¼Œä½ ç›®å‰æ‰“ç®—çš„æ€è€ƒæ–¹å‘æ˜¯ï¼š{comps['thinking_guidance_block']}",  # ä¿æŒæ ¼å¼
                intrusive_thought=f"ä½ çªç„¶æœ‰ä¸€ä¸ªç¥å¥‡çš„å¿µå¤´ï¼š{comps['intrusive_thought_block']}"
                if comps["intrusive_thought_block"]
                else "",
            )

            with st.expander("å‘é€ç»™ä¸»æ„è¯†LLMçš„å®Œæ•´Prompt (æ–°ç‰ˆUIç»„åˆç»“æœ)", expanded=False):
                st.text_area("", value=final_prompt_for_llm, height=400, disabled=True, key="new_final_prompt_display")

            with st.spinner("æ–°ç‰ˆUIçš„LLMä¹Ÿåœ¨åŠªåŠ›æ€è€ƒä¸­...å–µ..."):
                try:
                    response_data_new = asyncio.run(
                        st.session_state.main_llm_client.make_llm_request(prompt=final_prompt_for_llm, is_stream=False)
                    )
                    # (åç»­çš„JSONè§£æå’Œæ˜¾ç¤ºé€»è¾‘ï¼Œä¸åŸå§‹UIç‰ˆæœ¬ç±»ä¼¼)
                    if response_data_new.get("error"):
                        st.error(f"LLMè°ƒç”¨å¤±è´¥: {response_data_new.get('message')}")
                        st.session_state.last_thought_json_new = None
                        st.session_state.last_raw_response_new = f"LLM Error: {response_data_new.get('message')}"
                    else:
                        raw_text_new = response_data_new.get("text", "")
                        st.session_state.last_raw_response_new = raw_text_new
                        json_to_parse_new = raw_text_new.strip()
                        if json_to_parse_new.startswith("```json"):
                            json_to_parse_new = json_to_parse_new[7:-3].strip()
                        elif json_to_parse_new.startswith("```"):
                            json_to_parse_new = json_to_parse_new[3:-3].strip()
                        try:
                            st.session_state.last_thought_json_new = json.loads(json_to_parse_new)
                        except json.JSONDecodeError as e:
                            st.error(f"è§£æLLMçš„JSONå“åº”å¤±è´¥ (æ–°ç‰ˆUI): {e}")
                            st.session_state.last_thought_json_new = None
                except Exception as e_new_call:
                    st.error(f"åœ¨æ–°ç‰ˆUIç”Ÿæˆæ€è€ƒæ—¶å‘ç”Ÿé”™è¯¯: {e_new_call}", icon="ğŸ’¥")
                    st.exception(e_new_call)
                    st.session_state.last_thought_json_new = None
                    st.session_state.last_raw_response_new = str(e_new_call)

        if "last_raw_response_new" in st.session_state:
            with st.expander("ä¸»æ„è¯†LLMçš„åŸå§‹å›å¤ (æ–°ç‰ˆUI)", expanded=False):
                st.text_area(
                    "",
                    value=st.session_state.last_raw_response_new,
                    height=200,
                    disabled=True,
                    key="new_raw_output_display",
                )

        if "last_thought_json_new" in st.session_state and st.session_state.last_thought_json_new:
            st.subheader("ä¸»æ„è¯†LLMç»“æ„åŒ–è¾“å‡º (JSON) (æ–°ç‰ˆUI):")
            st.json(st.session_state.last_thought_json_new, expanded=True)
            if st.session_state.last_thought_json_new.get("action_to_take"):
                st.success("è€¶ï¼LLMåˆæƒ³æäº‹æƒ…äº† (æ–°ç‰ˆUI)ï¼å¯ä»¥å»æµ‹åŠ¨ä½œå†³ç­–ã€‚", icon="ğŸ‰")
                # (è¿™é‡Œä¹Ÿå¯ä»¥æ¥ç»­åˆ°åŠ¨ä½œå†³ç­–çš„UIéƒ¨åˆ†ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼Œé€»è¾‘ä¸åŸå§‹UIç‰ˆæœ¬ç±»ä¼¼)
            else:
                st.info("LLMè¿™æ¬¡å¾ˆä¹–ï¼Œæ²¡å•¥è¡ŒåŠ¨æ„å›¾ (æ–°ç‰ˆUI)ã€‚", icon="ğŸ§¸")


# --- ä¸»åº”ç”¨é€»è¾‘ ---
def main_app() -> None:
    st.set_page_config(layout="wide", page_title="å°æ‡’çŒ« Prompt æµ‹è¯•ä¹å›­ V2.1")  # æ”¹ä¸‹æ ‡é¢˜
    initialize_session_state()  # åˆå§‹åŒ–æˆ–æ¢å¤ä¼šè¯çŠ¶æ€
    llm_configuration_sidebar()  # æ˜¾ç¤ºé…ç½®ä¾§è¾¹æ 

    # é¡µé¢å¯¼èˆª
    page_options = {"åŸå§‹ç‰ˆæœ¬æµ‹è¯•å™¨ (æ—§)": show_original_ui, "ä»¿æˆªå›¾ç‰ˆæœ¬æµ‹è¯•å™¨ (æ–°)": show_new_ui}

    # ä½¿ç”¨ st.session_state.current_page æ¥æ§åˆ¶å½“å‰é¡µé¢
    # é€šè¿‡æŒ‰é’®æˆ– selectbox æ”¹å˜ st.session_state.current_page
    # ä¸ºäº†ç®€å•ï¼Œè¿™é‡Œç”¨ radio

    # st.sidebar.title("é¡µé¢å¯¼èˆª NekoNaviâ„¢ V2") #ç§»åˆ°llm_configuration_sidebarä¸‹é¢
    with st.sidebar:  # æŠŠå¯¼èˆªä¹Ÿæ”¾ä¾§è¾¹æ 
        st.markdown("---")
        st.title("é¡µé¢å¯¼èˆª NekoNaviâ„¢ V2")
        chosen_page_title = st.radio(
            "é€‰æ‹©ä¸€ä¸ªæµ‹è¯•é¡µé¢ç©ç©å§:",
            options=list(page_options.keys()),
            key="page_selector_radio",
            # index=list(page_options.keys()).index(st.session_state.current_page) # ä¿æŒé€‰æ‹©
        )
    st.session_state.current_page = chosen_page_title

    # è°ƒç”¨é€‰å®šé¡µé¢çš„å‡½æ•°
    if st.session_state.current_page in page_options:
        page_options[st.session_state.current_page]()
    else:  # é»˜è®¤æ˜¾ç¤ºåŸå§‹UI
        show_original_ui()


if __name__ == "__main__":
    main_app()
