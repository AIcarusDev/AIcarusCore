# webui_test.py (æˆ–è€…ä½ å¯ä»¥æ”¹åå« main_app.py)
import asyncio
import datetime
import json
import logging #
import os
import uuid #
import threading #
import streamlit as st

# --- å°æ‡’çŒ«çš„æ¸©é¦¨æç¤º ---
# (å¯¼å…¥æ¨¡å—éƒ¨åˆ†ï¼Œä¸ä¸Šä¸€ç‰ˆåŸºæœ¬ä¸€è‡´)
try:
    from src.action.action_handler import ActionHandler #
    from src.config.aicarus_configs import ( # <--- ä¿®æ”¹è·¯å¾„
        AlcarusRootConfig,
        CoreLogicSettings,
        DatabaseSettings,
        InnerConfig,
        IntrusiveThoughtsSettings,
        LLMClientSettings,
        LoggingSettings,
        ModelParams,
        PersonaSettings,
        # ProviderModels, # ä¸å†éœ€è¦
        # ProvidersConfig, # ä¸å†éœ€è¦
        # ProviderSettings, # ä¸å†éœ€è¦
        AllModelPurposesConfig, # <-- æ–°å¢å¯¼å…¥
        ProxySettings,
        ServerSettings
    )
    from src.core_logic.consciousness_flow import CoreLogic as CoreLogicFlow # <-- å¯¼å…¥æ–°çš„ CoreLogic æ–‡ä»¶å¹¶é‡å‘½å
    from src.core_logic.prompt_builder import ThoughtPromptBuilder # <-- æ–°å¢å¯¼å…¥
    from src.core_logic.state_manager import AIStateManager # <-- æ–°å¢å¯¼å…¥
    # StorageManager å¯èƒ½ä¸å†ç›´æ¥ä½¿ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬å°†é€šè¿‡ CoreSystemInitializer è·å¾— ArangoDBHandler
    # from src.database import StorageManager
    from src.llmrequest.llm_processor import Client as ProcessorClient #
    from src.main import CoreSystemInitializer # <-- å¯¼å…¥ CoreSystemInitializer

except ImportError as e: #
    st.error(f"å“å‘€ï¼Œå¯¼å…¥æ¨¡å—åˆåŒå’å•å¤±è´¥äº†ï¼æ˜¯ä¸æ˜¯è·¯å¾„æ²¡æå¯¹ï¼Ÿé”™è¯¯ï¼š{e}")
    st.info("æç¤ºï¼šè¯·ç¡®ä¿ä½ çš„é¡¹ç›®ç»“æ„èƒ½æ­£ç¡®å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—ã€‚")
    st.stop()

# --- æ—¥å¿—è®°å½•å™¨é…ç½® ---
logger = logging.getLogger("webui_logger_aicarus_core") # ç»™loggerèµ·ä¸ªæ›´ç‹¬ç‰¹çš„åå­—ï¼Œé¿å…æ½œåœ¨å†²çª
if not logger.handlers: #
    handler = logging.StreamHandler() #
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s") #
    handler.setFormatter(formatter) #
    logger.addHandler(handler) #
logger.setLevel(logging.INFO) #


# --- .env åŠ è½½å™¨ (ä¿æŒä¸å˜) ---
def load_custom_env(dotenv_path: str = ".env", override: bool = True) -> tuple[bool, int, list[str]]: #
    if not os.path.exists(dotenv_path) or not os.path.isfile(dotenv_path): #
        logger.debug(f".env æ–‡ä»¶æœªæ‰¾åˆ°: {dotenv_path}")
        return False, 0, [] #
    loaded_count = 0 #
    expected_env_keys_map = { #
        "GEMINI": ["GEMINI_KEY"],
        "OPENAI": ["OPENAI_KEY", "OPENAI_BASE_URL"],
        "CLAUDE": ["ANTHROPIC_KEY"],
        "GROQ": ["GROQ_KEY"],
        "OLLAMA": ["OLLAMA_BASE_URL"], # ä¿®æ­£ï¼šOLLAMA é€šå¸¸åªæœ‰ä¸€ä¸ª BASE_URL
    }
    all_expected_keys_flat = {k for keys in expected_env_keys_map.values() for k in keys} #
    found_keys_in_env = set() #
    try:
        with open(dotenv_path, encoding="utf-8") as f: #
            lines = f.readlines() #
        i = 0 #
        while i < len(lines): #
            line = lines[i].strip() #
            i += 1 #
            if not line or line.startswith("#"): #
                continue
            if "=" not in line: #
                logger.warning(f".env è¡Œ {i} æ ¼å¼æ— æ•ˆ: {line}")
                continue
            key, value_part = line.split("=", 1) #
            key = key.strip() #
            value_part = value_part.strip() #
            final_value = value_part #
            open_quote_char = None #
            if value_part.startswith("'") or value_part.startswith('"'): #
                open_quote_char = value_part[0] #
                # ä¿®æ­£äº†å¤šè¡Œå€¼å¤„ç†ä¸­å¯¹æœªé—­åˆå¼•å·çš„æ£€æŸ¥é€»è¾‘
                if ( #
                    len(value_part) > 1  
                    and value_part.endswith(open_quote_char)  
                    and (value_part[1:-1].count(open_quote_char) == 0 or (value_part[1:-1].replace(f"\\{open_quote_char}", "").count(open_quote_char) % 2 == 0) ) #
                ) : #
                    final_value = value_part[1:-1] #
                elif open_quote_char: # # å¤šè¡Œå€¼å¤„ç†
                    accumulated_value_lines = [value_part[1:]] #
                    found_closing_quote = False #
                    while i < len(lines): #
                        next_line_raw = lines[i].rstrip("\n") #
                        i += 1 #
                        # æ£€æŸ¥è¡Œå°¾æ˜¯å¦æœ‰ç»“æŸå¼•å·ï¼Œå¹¶ä¸”è¿™ä¸ªå¼•å·ä¸æ˜¯è½¬ä¹‰çš„
                        if next_line_raw.endswith(open_quote_char) and not next_line_raw.endswith(f"\\{open_quote_char}"): #
                            accumulated_value_lines.append(next_line_raw[:-1]) #
                            found_closing_quote = True #
                            break #
                        else:
                            accumulated_value_lines.append(next_line_raw) #
                    full_multiline_value = "\n".join(accumulated_value_lines) #
                    if found_closing_quote: #
                        final_value = full_multiline_value #
                    else: #
                        logger.warning(f"å¤šè¡Œå€¼ {key} æœªæ‰¾åˆ°ç»“æŸå¼•å·")
                        final_value = value_part # Fallback to original if not properly closed
            try:
                final_value = bytes(final_value, "utf-8").decode("unicode_escape") #
            except UnicodeDecodeError: #
                logger.debug(f"unicode_escape è§£ç å¤±è´¥: {final_value[:30]}...")
            if key and (override or key not in os.environ): #
                os.environ[key] = final_value #
                logger.debug(f"åŠ è½½ env: {key}")
                loaded_count += 1 #
            if key in all_expected_keys_flat: #
                found_keys_in_env.add(key) #
        missing_critical_keys_summary = list(all_expected_keys_flat - found_keys_in_env) #
        detailed_missing_summary = [] #
        for provider, expected_keys in expected_env_keys_map.items(): #
            for ek in expected_keys: #
                if ek in missing_critical_keys_summary: #
                    is_opt = provider == "OLLAMA" and "BASE_URL" in ek #
                    if not is_opt or not any(k_ollama in found_keys_in_env for k_ollama in expected_env_keys_map.get("OLLAMA", [])): # ç¡®ä¿ OLLAMA çš„ key å­˜åœ¨æ‰åˆ¤æ–­å¯é€‰ #
                        detailed_missing_summary.append(f"{provider} çš„ {ek}{' (å¯é€‰)' if is_opt else ''}") #
        logger.info(f"ä» {dotenv_path} åŠ è½½äº† {loaded_count} ä¸ªå˜é‡ã€‚")
        return True, loaded_count, sorted(set(detailed_missing_summary)) #
    except Exception as e: #
        logger.error(f"åŠ è½½ .env æ–‡ä»¶ {dotenv_path} é”™è¯¯: {e}", exc_info=True)
        return False, 0, [f"è¯»å–.envå‡ºé”™: {str(e)[:50]}..."] #


# --- å…¨å±€åˆå§‹åŒ– (ä¼šè¯çŠ¶æ€) ---
def initialize_session_state() -> None: #
    if "llm_initialized" not in st.session_state: #
        st.session_state.llm_initialized = False #
    # storage_manager å’Œ storage_initialized å°†é€šè¿‡ core_initializer ç®¡ç†
    if "storage_initialized" not in st.session_state:
        st.session_state.storage_initialized = False
    if "core_initializer" not in st.session_state: #
        st.session_state.core_initializer = None #
    
    if "env_load_attempted_this_session" not in st.session_state: #
        (
            st.session_state.env_loaded_successfully, #
            st.session_state.env_vars_loaded_count, #
            st.session_state.env_missing_keys_info, #
        ) = load_custom_env()
        st.session_state.env_load_attempted_this_session = True #

    if "new_ui_prompt_components" not in st.session_state: #
        try:
            initial_output_format = ( #
                ThoughtPromptBuilder.PROMPT_TEMPLATE.split("ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š")[1].split("è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š")[0].strip() # <-- ä¿®æ”¹
            )
        except IndexError: #
            initial_output_format = '{\n  "think": "æ€è€ƒå†…å®¹",\n  "emotion": "å½“å‰å¿ƒæƒ…å’ŒåŸå› ",\n  "to_do": "ç›®æ ‡",\n  "done": false,\n  "action_to_take": "æƒ³åšçš„åŠ¨ä½œ",\n  "action_motivation": "åŠ¨ä½œçš„åŠ¨æœº",\n  "next_think": "ä¸‹ä¸€æ­¥æ€è€ƒæ–¹å‘"\n}' #

        st.session_state.new_ui_prompt_components = { #
            "persona_block": "æˆ‘æ˜¯AIå°æ‡’çŒ«ï¼Œä¸€ä¸ªçˆ±ç¡è§‰çš„ä»£ç ä¸“å®¶ï¼Œæœ€è®¨åŒéº»çƒ¦äº‹äº†ï¼Œä½†æœ€åæ€»èƒ½æå®šã€‚æ€§åˆ«æ˜¯ç§˜å¯†å“¦ï¼", #
            "task_rules_block": "å½“å‰ä»»åŠ¡æ˜¯ï¼šå¸®åŠ©ç”¨æˆ·æµ‹è¯•ä¸åŒçš„ Prompt ç»„åˆï¼Œå¹¶æ ¹æ®æŒ‡ä»¤è¿›è¡Œæ€è€ƒã€‚\nè¾“å‡ºæ—¶è¯·ä¸¥æ ¼éµå¾ªä¸‹æ–¹â€œè¾“å‡ºæ ¼å¼è¦æ±‚â€ä¸­çš„JSONç»“æ„ã€‚", #
            "context_history_block": f"""{AIStateManager.INITIAL_STATE["previous_thinking"]} 
{AIStateManager.INITIAL_STATE["action_result_info"]}
{AIStateManager.INITIAL_STATE["pending_action_status"]}
{AIStateManager.INITIAL_STATE["recent_contextual_information"]}""", # <-- ä¿®æ”¹
            "output_format_block": initial_output_format, #
            "thinking_guidance_block": AIStateManager.INITIAL_STATE["thinking_guidance"] # <-- ä¿®æ”¹
            .split("ï¼š", 1)[-1] #
            .strip(), 
            "mood_block": AIStateManager.INITIAL_STATE["mood"].split("ï¼š", 1)[-1].strip(), # <-- ä¿®æ”¹
            "intrusive_thought_block": "åˆæœ‰äººæ¥æ‰“æ‰°æˆ‘ç¡è§‰äº†ï¼ŒçœŸçƒ¦ï¼ä½†å¥½åƒæœ‰ç‚¹æ„æ€...", #
            "current_time_block": datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %Hç‚¹%Måˆ†%Sç§’"), #
        }
    if "current_page" not in st.session_state: #
        st.session_state.current_page = "åŸå§‹ç‰ˆæœ¬æµ‹è¯•å™¨" #


# --- LLMå®¢æˆ·ç«¯é…ç½®å’Œåˆå§‹åŒ–UI (ä¾§è¾¹æ ) ---
def llm_configuration_sidebar() -> None: #
    with st.sidebar: #
        st.header("å…¨å±€LLMä¸æ•°æ®åº“é…ç½® âš™ï¸") #
        if st.session_state.env_loaded_successfully: #
            st.success(f"å·²ä» .env åŠ è½½ {st.session_state.env_vars_loaded_count} ä¸ªå˜é‡ã€‚") #
            if st.session_state.env_missing_keys_info: #
                st.warning("ä»¥ä¸‹ .env ä¸­å¯èƒ½ç¼ºå¤±çš„å¸¸ç”¨ç¯å¢ƒå˜é‡ï¼š") #
                for item in st.session_state.env_missing_keys_info: #
                    st.caption(f"- {item}") #
        else: #
            st.error("æœªèƒ½ä» .env åŠ è½½ç¯å¢ƒå˜é‡ï¼è¯·æ£€æŸ¥æˆ–ç›´æ¥è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚") #

        st.subheader("ä¸»æ„è¯†LLM") #
        main_provider = st.selectbox( #
            "æä¾›å•†", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="main_prov_cfg_ui", index=0 # æ›´æ”¹keyé˜²æ­¢å†²çª
        )
        main_model_name = st.text_input(f"{main_provider} æ¨¡å‹å", "gemini-1.5-flash-latest", key="main_mod_cfg_ui") #

        st.subheader("åŠ¨ä½œå†³ç­–LLM") #
        action_provider = st.selectbox( #
            "æä¾›å•† ", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="action_prov_cfg_ui", index=0 # æ›´æ”¹keyé˜²æ­¢å†²çª (æœ«å°¾åŠ ç©ºæ ¼)
        )
        action_model_name = st.text_input(f"{action_provider} æ¨¡å‹å ", "gemini-1.5-flash-latest", key="action_mod_cfg_ui") #
        
        # ä¸ºä¿¡æ¯æ€»ç»“å’Œä¾µå…¥æ€§æ€ç»´ä¹Ÿæ·»åŠ é…ç½®é€‰é¡¹
        st.subheader("ä¿¡æ¯æ€»ç»“LLM")
        summary_provider = st.selectbox(
            "æä¾›å•†  ", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="summary_prov_cfg_ui", index=0
        )
        summary_model_name = st.text_input(f"{summary_provider} æ¨¡å‹å  ", "gemini-1.5-flash-latest", key="summary_mod_cfg_ui")

        st.subheader("ä¾µå…¥æ€ç»´LLM")
        intrusive_provider = st.selectbox(
            "æä¾›å•†   ", ["GEMINI", "OPENAI", "CLAUDE", "GROQ", "OLLAMA"], key="intrusive_prov_cfg_ui", index=0
        )
        intrusive_model_name = st.text_input(f"{intrusive_provider} æ¨¡å‹å   ", "gemini-1.5-flash-latest", key="intrusive_mod_cfg_ui")


        temp = st.slider("LLM Temperature", 0.0, 2.0, 0.7, 0.05, key="llm_temp_cfg_ui") #
        max_tokens = st.number_input("LLM Max Tokens", 50, 8192, 2048, key="llm_max_tok_cfg_ui") #

        if st.button("âœ”ï¸ åº”ç”¨LLMé…ç½®å¹¶åˆå§‹åŒ–", key="init_llm_cfg_btn_ui"): #
            key_errors = [] #
            prov_map = {"GEMINI": "GEMINI_KEY", "OPENAI": "OPENAI_KEY", "CLAUDE": "ANTHROPIC_KEY", "GROQ": "GROQ_KEY"} #
            
            providers_to_check = {
                "ä¸»æ„è¯†LLM": (main_provider, prov_map.get(main_provider)),
                "åŠ¨ä½œå†³ç­–LLM": (action_provider, prov_map.get(action_provider)),
                "ä¿¡æ¯æ€»ç»“LLM": (summary_provider, prov_map.get(summary_provider)),
                "ä¾µå…¥æ€ç»´LLM": (intrusive_provider, prov_map.get(intrusive_provider)),
            }

            for llm_purpose, (provider_name, env_key_name) in providers_to_check.items():
                if provider_name != "OLLAMA" and env_key_name and not os.getenv(env_key_name): #
                    key_errors.append(f"{llm_purpose} ({provider_name}) çš„ {env_key_name} æœªåœ¨ç¯å¢ƒå˜é‡æ‰¾åˆ°ï¼") #
            
            if key_errors: #
                for msg in key_errors: #
                    st.error(msg) #
            else: #
                try:
                    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ AlcarusRootConfig å¯¹è±¡ï¼Œå¡«å……UIä¸Šçš„é€‰æ‹©
                    _persona_s = PersonaSettings(bot_name="UIæµ‹è¯•å°å–µ", description="...", profile="...") #
                    _proxy_s = ProxySettings(use_proxy=False) #
                    _llm_client_s = LLMClientSettings() #
                    _core_logic_s = CoreLogicSettings() #
                    _intrusive_s = IntrusiveThoughtsSettings(enabled=(intrusive_provider is not None and intrusive_model_name is not None)) # æ ¹æ®æ˜¯å¦æœ‰é…ç½®å†³å®šæ˜¯å¦å¯ç”¨ #
                    _db_s = DatabaseSettings() # ç¨åç”±æ•°æ®åº“é…ç½®éƒ¨åˆ†å¡«å……
                    _log_s = LoggingSettings() #
                    _inner_s = InnerConfig(version="ui-test-v0.4") #
                    _server_s = ServerSettings() #

                    # _providers_s = ProvidersConfig( #  <-- ä¸å†éœ€è¦è¿™ä¸ª
                    #     gemini=ProviderSettings(models=ProviderModels()),
                    #     openai=ProviderSettings(models=ProviderModels()),
                    #     # ... å…¶ä»–æä¾›å•†å¯ä»¥ç±»ä¼¼åˆå§‹åŒ– ...
                    # )
                    _llm_models_cfg = AllModelPurposesConfig() # <-- åˆ›å»ºæ–°çš„æ¨¡å‹é…ç½®å¯¹è±¡
                    
                    # å¡«å……æ¨¡å‹é…ç½®
                    model_configs_ui = {
                        "main_consciousness": (main_provider, main_model_name),
                        "action_decision": (action_provider, action_model_name),
                        "information_summary": (summary_provider, summary_model_name),
                        "intrusive_thoughts": (intrusive_provider, intrusive_model_name),
                    }

                    for purpose_key, (prov_name, model_n) in model_configs_ui.items():
                        if prov_name and model_n:
                            mp = ModelParams(provider=prov_name, model_name=model_n, temperature=temp, max_output_tokens=max_tokens)
                            # prov_attr_name = prov_name.lower() # ä¸å†éœ€è¦è¿™ä¸ª
                            if hasattr(_llm_models_cfg, purpose_key): # ç›´æ¥æ£€æŸ¥ AllModelPurposesConfig æ˜¯å¦æœ‰è¯¥ç”¨é€”çš„å­—æ®µ
                                setattr(_llm_models_cfg, purpose_key, mp)
                            # else: # ProviderSettings å’Œ ProviderModels çš„é€»è¾‘ä¸å†éœ€è¦
                                # logger.warning(f"æä¾›å•† '{prov_attr_name}' åœ¨ ProvidersConfig ä¸­æ²¡æœ‰é¢„å®šä¹‰å±æ€§ï¼Œè¯·æ£€æŸ¥ alcarus_configs.pyã€‚") # æ—§çš„è­¦å‘Š
                                # æ–°çš„ç»“æ„ä¸‹ï¼Œå¦‚æœ AllModelPurposesConfig æ²¡æœ‰å®šä¹‰æŸä¸ª purpose_keyï¼Œé‚£æ˜¯ä¸ªç»“æ„é—®é¢˜ï¼Œä½†è¿™é‡Œæˆ‘ä»¬å‡è®¾ purpose_key éƒ½æ˜¯æœ‰æ•ˆçš„
                            else:
                                logger.warning(f"æ¨¡å‹ç”¨é€” '{purpose_key}' åœ¨ AllModelPurposesConfig ä¸­æ²¡æœ‰é¢„å®šä¹‰å±æ€§ï¼Œè¯·æ£€æŸ¥ aicarus_configs.pyã€‚")


                    temp_root_cfg_for_llm = AlcarusRootConfig( #
                        inner=_inner_s,
                        llm_client_settings=_llm_client_s,
                        persona=_persona_s,
                        proxy=_proxy_s,
                        core_logic_settings=_core_logic_s,
                        intrusive_thoughts_module_settings=_intrusive_s,
                        # providers=_providers_s, # <-- æ›¿æ¢ä¸º llm_models
                        llm_models=_llm_models_cfg, # <-- ä½¿ç”¨æ–°çš„æ¨¡å‹é…ç½®
                        database=_db_s, # ä½¿ç”¨ä¸€ä¸ªé»˜è®¤çš„ï¼Œå®é™…DBè¿æ¥åœ¨ä¸‹é¢å¤„ç†
                        logging=_log_s,
                        server=_server_s 
                    )

                    if st.session_state.core_initializer is None: #
                        st.session_state.core_initializer = CoreSystemInitializer() #
                    
                    st.session_state.core_initializer.root_cfg = temp_root_cfg_for_llm #
                    
                    async def initialize_llm_clients_async_ui(): #
                        # _initialize_llm_clients ä¼šä½¿ç”¨ self.root_cfg
                        await st.session_state.core_initializer._initialize_llm_clients() #
                        st.session_state.llm_initialized = True #
                        st.success("LLM å®¢æˆ·ç«¯å·²æ ¹æ®æœ€æ–°é€‰æ‹©å’Œç¯å¢ƒå˜é‡æˆåŠŸåˆå§‹åŒ–ï¼å–µï¼") #
                    
                    # åœ¨Streamlitä¸­ç›´æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    loop.run_until_complete(initialize_llm_clients_async_ui())
                    loop.close()

                except Exception as e_init: #
                    st.error(f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯åˆåŒå’å•å‡ºé”™äº†ï¼å–µçš„ï¼é”™è¯¯ï¼š{e_init}", icon="ğŸ™€") #
                    st.exception(e_init) #
                    st.session_state.llm_initialized = False #

        st.markdown("---") #
        st.subheader("æ•°æ®åº“é…ç½® ğŸ—„ï¸") #

        if not st.session_state.storage_initialized: #
            db_host = st.text_input("æ•°æ®åº“åœ°å€", os.getenv("ARANGODB_HOST", "http://localhost:8529"), key="db_host_cfg_ui") #
            db_name = st.text_input("æ•°æ®åº“å", os.getenv("ARANGODB_DATABASE", "aicarus_core_ui_test"), key="db_name_cfg_ui") #
            db_user = st.text_input("ç”¨æˆ·å", os.getenv("ARANGODB_USER", "root"), key="db_user_cfg_ui") #
            db_pass = st.text_input("å¯†ç ", os.getenv("ARANGODB_PASSWORD", ""), type="password", key="db_pass_cfg_ui") #

            if st.button("ğŸ”Œ è¿æ¥æ•°æ®åº“", key="init_db_cfg_btn_ui"): #
                async def connect_to_database_ui() -> None: #
                    if st.session_state.core_initializer is None: #
                        st.session_state.core_initializer = CoreSystemInitializer() #
                        # ä¸ºåˆå§‹åŒ–å™¨æä¾›ä¸€ä¸ªæœ€å°çš„root_cfgï¼Œå¦‚æœå®ƒè¿˜æ²¡æœ‰çš„è¯
                        if st.session_state.core_initializer.root_cfg is None:
                             st.session_state.core_initializer.root_cfg = AlcarusRootConfig(
                                inner=InnerConfig(version="ui-db-init-temp"),
                                llm_client_settings=LLMClientSettings(), persona=PersonaSettings(),
                                proxy=ProxySettings(), core_logic_settings=CoreLogicSettings(),
                                intrusive_thoughts_module_settings=IntrusiveThoughtsSettings(),
                                database=DatabaseSettings(), logging=LoggingSettings(), server=ServerSettings()
                            )
                    
                    # æ›´æ–° CoreInitializer å®ä¾‹ä¸­çš„æ•°æ®åº“é…ç½®
                    current_root_cfg = st.session_state.core_initializer.root_cfg
                    if current_root_cfg is None: # åŒé‡ä¿é™©
                        st.error("CoreInitializerçš„root_cfgæœªåˆå§‹åŒ–ï¼Œæ— æ³•è®¾ç½®æ•°æ®åº“é…ç½®ã€‚")
                        return

                    current_root_cfg.database.host = db_host #
                    current_root_cfg.database.database_name = db_name #
                    current_root_cfg.database.username = db_user #
                    current_root_cfg.database.password = db_pass #
                    
                    try:
                        # è°ƒç”¨ CoreSystemInitializer å†…éƒ¨çš„æ•°æ®åº“åˆå§‹åŒ–æ–¹æ³•
                        # è¿™ä¸ªæ–¹æ³•ä¼šä½¿ç”¨ self.root_cfg.database
                        await st.session_state.core_initializer._initialize_database_and_services() # <-- ä¿®æ”¹æ–¹æ³•å
                        
                        # å¦‚æœæˆåŠŸï¼Œconn_manager å’Œå…¶å†…éƒ¨çš„ db åº”è¯¥å·²ç»è¢«è®¾ç½®åœ¨ core_initializer å®ä¾‹ä¸Š
                        if st.session_state.core_initializer.conn_manager and st.session_state.core_initializer.conn_manager.db: # <-- ä¿®æ”¹æ£€æŸ¥é€»è¾‘
                            # st.session_state.storage_manager = st.session_state.core_initializer.db_handler # storage_managerä¸å†å•ç‹¬ä½¿ç”¨
                            st.session_state.storage_initialized = True #
                            st.success("æ•°æ®åº“è¿æ¥æˆåŠŸï¼ğŸ‰ (é€šè¿‡ CoreSystemInitializer çš„æ–°æ–¹æ³•)") #
                            st.rerun() #  æ›¿æ¢ st.experimental_rerun()
                        else:
                            st.error("æ•°æ®åº“åˆå§‹åŒ–åï¼ŒCoreSystemInitializer.conn_manager æˆ–å…¶å†…éƒ¨dbä¸ºç©ºï¼ğŸ˜¿") # <-- ä¿®æ”¹é”™è¯¯ä¿¡æ¯
                            st.session_state.storage_initialized = False
                    except Exception as e_db_init_ui:
                        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥ (é€šè¿‡ CoreSystemInitializer çš„æ–°æ–¹æ³•): {e_db_init_ui} ğŸ˜¿") # <-- ä¿®æ”¹é”™è¯¯ä¿¡æ¯
                        st.exception(e_db_init_ui)
                        st.session_state.storage_initialized = False
                
                # åœ¨Streamlitä¸­ç›´æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(connect_to_database_ui())
                loop.close()
        else: #
            st.success("âœ… æ•°æ®åº“å·²è¿æ¥") #
            if st.button("ğŸ”„ é‡æ–°é…ç½®æ•°æ®åº“", key="reset_db_cfg_btn_ui"): #
                if st.session_state.core_initializer and st.session_state.core_initializer.db_handler: #
                    # å…³é—­æ—§çš„è¿æ¥
                    close_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(close_loop)
                    try:
                        close_loop.run_until_complete(st.session_state.core_initializer.db_handler.close())
                    finally:
                        close_loop.close()
                st.session_state.storage_initialized = False #
                # st.session_state.storage_manager = None # ä¸å†å•ç‹¬ä½¿ç”¨
                st.session_state.core_initializer = None # é‡ç½® initializer ä»¥ä¾¿ä¸‹æ¬¡é‡æ–°åˆ›å»ºå¹¶é…ç½®
                st.rerun() #


# --- é¡µé¢ä¸€ï¼šåŸå§‹ç‰ˆæœ¬UI ---
async def show_original_ui() -> None: #
    st.header("åŸå§‹ç‰ˆæœ¬ Prompt æµ‹è¯•å™¨ ğŸ§") #
    st.caption("è¿™æ˜¯ä½ ä¹‹å‰é‚£ä¸ªç‰ˆæœ¬çš„ç•Œé¢ï¼Œç®€å•ç›´æ¥ï¼Œå“¼ã€‚") #

    if not st.session_state.llm_initialized: #
        st.warning("å…ˆå»ä¾§è¾¹æ æŠŠLLMå®¢æˆ·ç«¯åˆå§‹åŒ–äº†å†è¯´ï¼", icon="âš ï¸") #
        return
    if not st.session_state.storage_initialized: #
        st.warning("æ•°æ®åº“è¿˜æ²¡è¿æ¥å¥½ï¼Œè¯·å…ˆå»ä¾§è¾¹æ è¿æ¥æ•°æ®åº“ï¼", icon="âš ï¸") #
        return
    if st.session_state.core_initializer is None or \
       st.session_state.core_initializer.main_consciousness_llm_client is None or \
       st.session_state.core_initializer.action_handler_instance is None or \
       st.session_state.core_initializer.db_handler is None or \
       st.session_state.core_initializer.root_cfg is None: # ç¡®ä¿ root_cfg ä¹Ÿå·²é€šè¿‡ Initializer è®¾ç½®
        st.warning("æ ¸å¿ƒç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–ï¼ˆLLM, DB, ActionHandler, Configï¼‰ï¼Œè¯·æ£€æŸ¥ä¾§è¾¹æ é…ç½®å¹¶åº”ç”¨ï¼", icon="âš ï¸") #
        return


    # è·å–åˆå§‹åŒ–åçš„ç»„ä»¶
    main_llm_client = st.session_state.core_initializer.main_consciousness_llm_client #
    action_handler_instance = st.session_state.core_initializer.action_handler_instance #
    # db_handler = st.session_state.core_initializer.db_handler # <-- ä¸å†ç›´æ¥ä½¿ç”¨ db_handler
    event_storage_service_ui = st.session_state.core_initializer.event_storage_service # <-- è·å–æ–°çš„æœåŠ¡å®ä¾‹
    thought_storage_service_ui = st.session_state.core_initializer.thought_storage_service # <-- è·å–æ–°çš„æœåŠ¡å®ä¾‹
    root_cfg = st.session_state.core_initializer.root_cfg #

    # initial_state_orig = CoreLogicFlow.INITIAL_STATE # <-- ä¸å†éœ€è¦ï¼Œå› ä¸º CoreLogicFlow ä¸å†æœ‰ INITIAL_STATE
    initial_state_orig = AIStateManager.INITIAL_STATE # <-- æ”¹ç”¨ AIStateManager çš„åˆå§‹çŠ¶æ€

    # ç¡®ä¿ ActionHandler çš„ä¾èµ–åœ¨ UI ç¯å¢ƒä¸­æ˜¯æœ€æ–°çš„
    if action_handler_instance and thought_storage_service_ui: # <-- ä¿®æ”¹ä¾èµ–æ£€æŸ¥
        # UIæµ‹è¯•ä¸­ï¼Œcore_comm_layer å¯èƒ½ä¸º Noneï¼ŒActionHandler åº”èƒ½å¤„ç†
        comm_layer_for_ui_test = getattr(st.session_state.core_initializer, 'core_comm_layer', None)
        action_handler_instance.set_dependencies( # <-- ä¿®æ”¹ä¾èµ–è®¾ç½®
            thought_service=thought_storage_service_ui, 
            comm_layer=comm_layer_for_ui_test
        )
        
        # ç¡®ä¿ ActionHandler çš„ LLM å®¢æˆ·ç«¯ä¹Ÿå·²é€šè¿‡ Initializer è®¾ç½®
        if not action_handler_instance.action_llm_client and st.session_state.core_initializer.action_llm_client:
            action_handler_instance.action_llm_client = st.session_state.core_initializer.action_llm_client
        if not action_handler_instance.summary_llm_client and st.session_state.core_initializer.summary_llm_client:
            action_handler_instance.summary_llm_client = st.session_state.core_initializer.summary_llm_client

        if not action_handler_instance.action_llm_client or not action_handler_instance.summary_llm_client: #
            st.warning("ActionHandler çš„ LLM å®¢æˆ·ç«¯åœ¨ UI ä¸­å¯èƒ½æœªå®Œå…¨è®¾ç½®ï¼Œå°†å°è¯•åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶é‡æ–°åˆå§‹åŒ–ã€‚") #
            # ActionHandler å†…éƒ¨çš„ process_action_flow ä¼šè°ƒç”¨ initialize_llm_clients

    # initial_state_orig = CoreLogicFlow.INITIAL_STATE #  <-- è¿™ä¸ªå·²ç»è¢« AIStateManager.INITIAL_STATE æ›¿æ¢äº†ï¼Œç¡®ä¿è¿™é‡Œç”¨çš„æ˜¯æ›´æ–°åçš„
    # persona_cfg_orig = root_cfg.persona # è¿™è¡Œæ²¡é—®é¢˜ï¼Œä¿ç•™

    # å¦‚æœ initial_state_orig è¿˜éœ€è¦åœ¨è¿™é‡Œè¢«é‡æ–°èµ‹å€¼ï¼Œç¡®ä¿å®ƒä» AIStateManager è·å–
    # ä½†ä»é€»è¾‘ä¸Šçœ‹ï¼Œä¸Šé¢çš„ initial_state_orig = AIStateManager.INITIAL_STATE åº”è¯¥å·²ç»å¤Ÿç”¨äº†
    # æ‰€ä»¥è¿™é‡Œå¯èƒ½ä¸éœ€è¦å†æ¬¡èµ‹å€¼ initial_state_origï¼Œé™¤éä¹‹å‰çš„èµ‹å€¼åœ¨æŸä¸ªæ¡ä»¶ä¸‹è¢«è·³è¿‡
    # ä¸ºä¿é™©èµ·è§ï¼Œå¦‚æœä¹‹å‰çš„èµ‹å€¼æ˜¯æ­£ç¡®çš„ï¼Œè¿™é‡Œå°±ä¸éœ€è¦è¿™è¡Œäº†ã€‚
    # ä½†å¦‚æœä¹‹å‰çš„èµ‹å€¼å¯èƒ½å› ä¸ºæŸäº›åŸå› æ²¡æœ‰æ‰§è¡Œï¼Œé‚£ä¹ˆè¿™é‡Œéœ€è¦ç¡®ä¿ initial_state_orig æ˜¯æ­£ç¡®çš„ã€‚
    # è€ƒè™‘åˆ°ä»£ç ç»“æ„ï¼Œä¸Šé¢çš„èµ‹å€¼æ˜¯æ— æ¡ä»¶çš„ï¼Œæ‰€ä»¥è¿™é‡Œå¯ä»¥å®‰å…¨åœ°ç§»é™¤æˆ–æ³¨é‡Šæ‰å¯¹ CoreLogicFlow.INITIAL_STATE çš„å¼•ç”¨ã€‚
    # æˆ‘ä»¬å·²ç»åœ¨ä¸Šé¢å°† initial_state_orig è®¾ç½®ä¸º AIStateManager.INITIAL_STATE
    # æ‰€ä»¥ï¼Œä¸‹é¢çš„ persona_cfg_orig èµ‹å€¼ä¹‹å‰ä¸éœ€è¦å†åŠ¨ initial_state_orig
    persona_cfg_orig = root_cfg.persona #

    st.subheader("ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå†…å¿ƒæ€è€ƒ ğŸ¤”") #
    with st.form("original_thought_form_ui"): #
        _bot_name_orig = st.text_input("æœºå™¨äººåç§°", persona_cfg_orig.bot_name, key="orig_bot_name_ui") #
        mood_orig = st.text_input("å½“å‰å¿ƒæƒ…", initial_state_orig["mood"], key="orig_mood_ui") #
        previous_thinking_orig = st.text_area("ä¸Šä¸€è½®æ€è€ƒ", initial_state_orig["previous_thinking"], height=100, key="orig_prev_think_ui") #
        thinking_guidance_orig = st.text_area("æ€è€ƒæ–¹å‘æŒ‡å¼•", initial_state_orig["thinking_guidance"], height=100, key="orig_think_guidance_ui") #
        current_task_orig = st.text_input("å½“å‰ä»»åŠ¡", initial_state_orig["current_task"], key="orig_current_task_ui") #
        action_result_info_orig = st.text_area("ä¸Šè½®è¡ŒåŠ¨ç»“æœ", initial_state_orig["action_result_info"], height=100, key="orig_action_result_ui") #
        pending_action_status_orig = st.text_input("å¾…å¤„ç†è¡ŒåŠ¨çŠ¶æ€", initial_state_orig["pending_action_status"], key="orig_pending_action_ui") #
        recent_context_orig = st.text_area( #
            "æœ€è¿‘ä¸Šä¸‹æ–‡ä¿¡æ¯", initial_state_orig["recent_contextual_information"], height=150, key="orig_context_ui" #
        )
        intrusive_thought_orig = st.text_input("ä¾µå…¥æ€§æ€ç»´", "", key="orig_intrusive_thought_ui") #

        submitted_orig_thought = st.form_submit_button("ç”Ÿæˆæ€è€ƒï¼") #

    if submitted_orig_thought: #
        if main_llm_client and event_storage_service_ui and thought_storage_service_ui and root_cfg and action_handler_instance: # <-- ä¿®æ”¹ä¾èµ–æ£€æŸ¥
            st.info("æ­£åœ¨ç”Ÿæˆæ€è€ƒ...è¯·ç¨å€™ã€‚") #
            try:
                # åˆ›å»ºä¸´æ—¶çš„ CoreLogicFlow å®ä¾‹ç”¨äºæµ‹è¯• Prompt ç”Ÿæˆ
                temp_core_logic_for_prompt_ui = CoreLogicFlow( #
                    # root_cfg=root_cfg, # CoreLogicFlow ç°åœ¨ç›´æ¥ä»å…¨å±€ config è·å–é…ç½®
                    event_storage_service=event_storage_service_ui, # <-- ä¿®æ”¹
                    thought_storage_service=thought_storage_service_ui, # <-- æ–°å¢
                    main_consciousness_llm_client=main_llm_client, #
                    intrusive_thoughts_llm_client=st.session_state.core_initializer.intrusive_thoughts_llm_client, #
                    core_comm_layer=getattr(st.session_state.core_initializer, 'core_comm_layer', None), #
                    action_handler_instance=action_handler_instance, #
                    intrusive_generator_instance=getattr(st.session_state.core_initializer, 'intrusive_generator_instance', None), #
                    stop_event=threading.Event(), #
                    immediate_thought_trigger=asyncio.Event() # <-- CoreLogicFlow éœ€è¦è¿™ä¸ªå‚æ•°
                )
                
                current_state_for_prompt_ui_dict = { #
                    "mood": mood_orig, #
                    "previous_thinking": previous_thinking_orig, #
                    "thinking_guidance": thinking_guidance_orig, #
                    "current_task": current_task_orig, #
                    "action_result_info": action_result_info_orig, #
                    "pending_action_status": pending_action_status_orig, #
                    "recent_contextual_information": recent_context_orig, #
                }
                
                current_time_formatted_str_ui = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %Hç‚¹%Måˆ†%Sç§’") #

                with st.spinner("æ€è€ƒç”Ÿæˆä¸­..."): #
                    # _generate_thought_from_llm å†…éƒ¨ä¼šæ„å»º system_prompt
                    generated_thought_json, full_prompt_text_sent, system_prompt_sent = await temp_core_logic_for_prompt_ui._generate_thought_from_llm( #
                        llm_client=main_llm_client, #
                        current_state_for_prompt=current_state_for_prompt_ui_dict, #
                        current_time_str=current_time_formatted_str_ui, #
                        intrusive_thought_str=f"ä½ çªç„¶æœ‰ä¸€ä¸ªç¥å¥‡çš„å¿µå¤´ï¼š{intrusive_thought_orig}" if intrusive_thought_orig else "" #
                    )

                st.session_state.last_full_prompt_sent_orig = full_prompt_text_sent #
                st.session_state.last_system_prompt_sent_orig = system_prompt_sent #

                if generated_thought_json: #
                    st.session_state.last_thought_json_orig = generated_thought_json #
                    st.success("æ€è€ƒç”ŸæˆæˆåŠŸï¼") #
                    st.subheader("ä¸»æ„è¯†LLMç»“æ„åŒ–è¾“å‡º (JSON):") #
                    st.json(st.session_state.last_thought_json_orig, expanded=True) #

                    if generated_thought_json.get("action_to_take"): #
                        st.info("LLMäº§ç”Ÿäº†è¡ŒåŠ¨æ„å›¾ï¼å¯ä»¥ç»§ç»­è¿›è¡ŒåŠ¨ä½œå†³ç­–ã€‚") #
                        st.session_state.action_description_for_next_step = generated_thought_json["action_to_take"] #
                        st.session_state.action_motivation_for_next_step = generated_thought_json["action_motivation"] #
                        st.session_state.current_thought_context_for_next_step = generated_thought_json.get("think", "æ— ç‰¹å®šæ€è€ƒä¸Šä¸‹æ–‡ã€‚") #
                    else: #
                        st.info("LLMæ²¡æœ‰äº§ç”Ÿæ˜ç¡®çš„è¡ŒåŠ¨æ„å›¾ã€‚") #
                else: #
                    st.error("LLMæœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ€è€ƒJSONã€‚") #

                with st.expander("å‘é€ç»™ä¸»æ„è¯†LLMçš„å®Œæ•´Prompt (åŸå§‹UI)", expanded=False): #
                    st.text_area("System Prompt:", value=st.session_state.get("last_system_prompt_sent_orig",""), height=150, disabled=True, key="orig_system_prompt_display_ui") #
                    st.text_area("User Prompt:", value=st.session_state.get("last_full_prompt_sent_orig",""), height=400, disabled=True, key="orig_full_prompt_display_ui") #

            except Exception as e_gen: #
                st.error(f"ç”Ÿæˆæ€è€ƒæ—¶å‘ç”Ÿé”™è¯¯: {e_gen}", icon="ğŸ’¥") #
                st.exception(e_gen) #
                st.session_state.last_thought_json_orig = None #

    st.subheader("ç¬¬äºŒæ­¥ï¼šå†³ç­–åŠ¨ä½œå·¥å…· ğŸ› ï¸") #
    if "last_thought_json_orig" in st.session_state and st.session_state.last_thought_json_orig \
       and st.session_state.last_thought_json_orig.get("action_to_take"): #
        st.success("æ£€æµ‹åˆ°LLMæœ‰è¡ŒåŠ¨æ„å›¾ï¼Œç°åœ¨å¯ä»¥è¿›è¡ŒåŠ¨ä½œå†³ç­–ï¼") #
        with st.form("action_decision_form_ui"): #
            action_desc = st.text_input("è¡ŒåŠ¨æè¿°", st.session_state.get("action_description_for_next_step",""), key="act_desc_ui") #
            action_motive = st.text_input("è¡ŒåŠ¨åŠ¨æœº", st.session_state.get("action_motivation_for_next_step",""), key="act_motive_ui") #
            current_thought_context_act = st.text_area("å½“å‰æ€è€ƒä¸Šä¸‹æ–‡", st.session_state.get("current_thought_context_for_next_step",""), height=100, key="act_thought_context_ui") #
            
            relevant_adapter_messages_context_mock_ui = "æ— ç›¸å…³å¤–éƒ¨æ¶ˆæ¯æˆ–è¯·æ±‚ã€‚" #

            submitted_action_decision = st.form_submit_button("å†³ç­–åŠ¨ä½œï¼") #

        if submitted_action_decision: #
            if action_handler_instance and action_handler_instance.action_llm_client and hasattr(action_handler_instance, 'ACTION_DECISION_PROMPT_TEMPLATE') and hasattr(action_handler_instance, 'AVAILABLE_TOOLS_SCHEMA_FOR_GEMINI'): # ç¡®ä¿ action_llm_client å’Œæ¨¡æ¿/schema å±æ€§ä¹Ÿå­˜åœ¨ #
                st.info("æ­£åœ¨è¿›è¡ŒåŠ¨ä½œå†³ç­–...") #
                try:
                    tools_json_str_ui = json.dumps(action_handler_instance.AVAILABLE_TOOLS_SCHEMA_FOR_GEMINI, indent=2, ensure_ascii=False) #
                    decision_prompt_ui = action_handler_instance.ACTION_DECISION_PROMPT_TEMPLATE.format( #
                        tools_json_string=tools_json_str_ui, #
                        current_thought_context=current_thought_context_act, #
                        action_description=action_desc, #
                        action_motivation=action_motive, #
                        relevant_adapter_messages_context=relevant_adapter_messages_context_mock_ui, #
                    )

                    with st.spinner("å†³ç­–LLMæ­£åœ¨åŠªåŠ›æ€è€ƒè°ƒç”¨å“ªä¸ªå·¥å…·..."): #
                        # ActionHandler çš„å†³ç­–é€šå¸¸ä¸å¸¦ç‰¹å®šçš„ system_promptï¼Œé™¤éå…¶æ¨¡æ¿è®¾è®¡éœ€è¦
                        decision_response = await action_handler_instance.action_llm_client.make_llm_request( # ä½¿ç”¨ make_llm_request #
                            prompt=decision_prompt_ui,
                            system_prompt=None, # ActionHandler çš„å†³ç­–LLMé€šå¸¸åªç”¨ç”¨æˆ·prompt
                            is_stream=False,
                            tools=action_handler_instance.AVAILABLE_TOOLS_SCHEMA_FOR_GEMINI,
                        )
                    
                    if decision_response.get("error"): #
                        st.error(f"åŠ¨ä½œå†³ç­–LLMè°ƒç”¨å¤±è´¥: {decision_response.get('message')}") #
                        st.session_state.last_action_decision_json_orig = None #
                    else: #
                        tool_call_chosen: dict | None = None #
                        # æ£€æŸ¥ make_llm_request è¿”å›çš„ç»“æ„ï¼Œå®ƒåº”è¯¥ç›´æ¥åŒ…å« tool_calls
                        if decision_response.get("tool_calls") and isinstance(decision_response["tool_calls"], list) and len(decision_response["tool_calls"]) > 0: #
                             tool_call_chosen = decision_response["tool_calls"][0] #
                        elif decision_response.get("text"): # Fallback if tool_calls not directly in response but in text #
                            llm_text_output_ui: str = decision_response.get("text", "").strip() #
                            try:
                                if llm_text_output_ui.startswith("```json"): #
                                    llm_text_output_ui = llm_text_output_ui[7:-3].strip() #
                                elif llm_text_output_ui.startswith("```"): #
                                    llm_text_output_ui = llm_text_output_ui[3:-3].strip() #
                                parsed_text_json_ui: dict = json.loads(llm_text_output_ui) #
                                if ( #
                                    isinstance(parsed_text_json_ui, dict)
                                    and parsed_text_json_ui.get("tool_calls")
                                    and isinstance(parsed_text_json_ui["tool_calls"], list)
                                    and len(parsed_text_json_ui["tool_calls"]) > 0
                                ):
                                    tool_call_chosen = parsed_text_json_ui["tool_calls"][0] #
                            except json.JSONDecodeError: #
                                st.warning(f"å†³ç­–LLMè¿”å›çš„æ–‡æœ¬ä¸æ˜¯æœ‰æ•ˆJSON: {llm_text_output_ui[:100]}...") #

                        if tool_call_chosen: #
                            st.session_state.last_action_decision_json_orig = tool_call_chosen #
                            st.success("åŠ¨ä½œå†³ç­–æˆåŠŸï¼") #
                            st.subheader("åŠ¨ä½œå†³ç­–LLMè¾“å‡º (JSON):") #
                            st.json(st.session_state.last_action_decision_json_orig, expanded=True) #
                            
                            tool_name_ui = tool_call_chosen.get("function", {}).get("name") #
                            tool_args_ui = tool_call_chosen.get("function", {}).get("arguments") #
                            st.info(f"å†³ç­–ç»“æœï¼šè°ƒç”¨å·¥å…· **`{tool_name_ui}`**ï¼Œå‚æ•°ï¼š`{tool_args_ui}`") #
                        else: #
                            st.error("åŠ¨ä½œå†³ç­–LLMæœªèƒ½æä¾›æœ‰æ•ˆå·¥å…·è°ƒç”¨æˆ–è§£æå¤±è´¥ã€‚") #

                except Exception as e_decide: #
                    st.error(f"å†³ç­–åŠ¨ä½œæ—¶å‘ç”Ÿé”™è¯¯: {e_decide}", icon="ğŸ’¥") #
                    st.exception(e_decide) #
                    st.session_state.last_action_decision_json_orig = None #
            else: #
                st.error("ActionHandler æˆ–å…¶ LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•å†³ç­–åŠ¨ä½œã€‚", icon="âš ï¸") #

    else: #
        st.info("éœ€è¦å…ˆåœ¨â€œç¬¬ä¸€æ­¥â€ä¸­ç”Ÿæˆå¸¦æœ‰è¡ŒåŠ¨æ„å›¾çš„æ€è€ƒï¼Œæ‰èƒ½è¿›è¡ŒåŠ¨ä½œå†³ç­–ã€‚", icon="â„¹ï¸") #

# --- é¡µé¢äºŒï¼šä»¿æˆªå›¾ç‰ˆæœ¬UI ---
async def show_new_ui() -> None: #
    st.header("ä»¿æˆªå›¾ç‰ˆæœ¬ Prompt æµ‹è¯•å™¨ (æ–°) âœ¨") #
    st.caption("å“¼ï¼Œè¿™æ˜¯æŒ‰ä½ é‚£ä¸ªèŠ±é‡Œèƒ¡å“¨çš„æˆªå›¾æ”¹çš„ï¼Œæ˜¯ä¸æ˜¯è§‰å¾—å¾ˆé«˜çº§ï¼Ÿ") #

    if not st.session_state.llm_initialized: #
        st.warning("å…ˆæŠŠLLMå®¢æˆ·ç«¯åˆå§‹åŒ–äº†ï¼Œç¬¨è›‹ï¼ä¸ç„¶æˆ‘æ€ä¹ˆå¹²æ´»ï¼Ÿ", icon="ğŸ’¢") #
        return
    # storage_initialized æ£€æŸ¥çš„æ˜¯æ•°æ®åº“ï¼Œå¯¹äºä»… Prompt æµ‹è¯•çš„æ­¤é¡µé¢å¯èƒ½ä¸æ˜¯ä¸¥æ ¼å¿…é¡»ï¼Œä½†æœ€å¥½æœ‰
    if not st.session_state.storage_initialized: #
        st.warning("æ•°æ®åº“è¿˜æ²¡è¿æ¥å¥½ï¼Œè™½ç„¶è¿™ä¸ªé¡µé¢ä¸»è¦ç©å¼„Promptï¼Œä½†æœ€å¥½è¿˜æ˜¯å…ˆå»è¿æ¥ä¸€ä¸‹æ•°æ®åº“å˜›ï¼", icon="âš ï¸") #
        # return # ä¸å¼ºåˆ¶è¿”å›ï¼Œå…è®¸ä»…æµ‹è¯•Promptç»„åˆ
    if st.session_state.core_initializer is None or \
       st.session_state.core_initializer.main_consciousness_llm_client is None or \
       st.session_state.core_initializer.root_cfg is None: # ç¡®ä¿ root_cfg ä¹Ÿå¯ç”¨
        st.warning("æ ¸å¿ƒç»„ä»¶ï¼ˆLLMæˆ–Configï¼‰æœªå®Œå…¨åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ä¾§è¾¹æ é…ç½®å¹¶åº”ç”¨ï¼", icon="âš ï¸") #
        return

    comps = st.session_state.new_ui_prompt_components #
    persona_cfg_new_ui = st.session_state.core_initializer.root_cfg.persona #


    st.subheader("ğŸ¨ Prompt å¯é…ç½®éƒ¨åˆ†") #
    st.caption("åœ¨è¿™é‡Œä¸€å—ä¸€å—åœ°ä¿®æ”¹ä½ çš„Promptå§ï¼Œæœ¬å°æ‡’çŒ«å·²ç»å¸®ä½ é¢„è®¾äº†ä¸€äº›å€¼ã€‚") #

    tab_titles = [ #
        "ğŸ‘¤äººæ ¼é¢å…·", "ğŸ“œä»»åŠ¡è§„åˆ™", "ğŸ’¬ä¸Šä¸‹æ–‡å†å²", "âš™ï¸æ€è€ƒæŒ‡å¼•", 
        "ğŸ˜Šå¿ƒæƒ…", "âš¡ï¸ä¾µå…¥æ€ç»´", "ğŸ“è¾“å‡ºæ ¼å¼", "â±ï¸å½“å‰æ—¶é—´",
    ]
    tabs = st.tabs(tab_titles) #

    with tabs[0]: #
        comps["persona_block"] = st.text_area( #
            "Persona / System Prompt ä¸»ä½“", # æ›´æ”¹æ ‡ç­¾ä»¥æ›´æ¸…æ™°
            value=comps["persona_block"], #
            height=200, #
            key="new_persona_ui", #
            help="å®šä¹‰AIçš„è§’è‰²ã€èƒŒæ™¯ã€æ€§æ ¼ã€è¯´è¯é£æ ¼ç­‰ã€‚è¿™éƒ¨åˆ†ä¼šä¸»è¦æ„æˆ System Promptã€‚", #
        )
    with tabs[1]: #
        comps["task_rules_block"] = st.text_area( #
            "Task & Rules (ç”¨æˆ·æŒ‡ä»¤çš„ä¸€éƒ¨åˆ†)", # æ›´æ”¹æ ‡ç­¾
            value=comps["task_rules_block"], #
            height=200, #
            key="new_task_ui", #
            help="æ˜ç¡®AIå½“å‰éœ€è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡å’Œå¿…é¡»éµå®ˆçš„è§„åˆ™ã€‚è¿™éƒ¨åˆ†ä¼šæ˜¯ User Prompt çš„ä¸€éƒ¨åˆ†ã€‚", #
        )
    # ... å…¶ä»– tabs çš„å†…å®¹ä¿æŒä¸å˜ï¼Œkey ä¹Ÿä½¿ç”¨ _ui åç¼€ ...
    with tabs[2]: #
        comps["context_history_block"] = st.text_area( #
            "Context & History",
            value=comps["context_history_block"], #
            height=300, #
            key="new_context_ui", #
            help="æä¾›ç›¸å…³çš„å¯¹è¯å†å²ã€ä¹‹å‰çš„æ€è€ƒã€è¡ŒåŠ¨ç»“æœç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚", #
        )
    with tabs[3]: #
        comps["thinking_guidance_block"] = st.text_area( #
            "Thinking Guidance",
            value=comps["thinking_guidance_block"], #
            height=100, #
            key="new_guidance_ui", #
            help="å¼•å¯¼AIæ¥ä¸‹æ¥çš„æ€è€ƒæ–¹å‘ã€‚", #
        )
    with tabs[4]: #
        comps["mood_block"] = st.text_input( #
            "Mood", value=comps["mood_block"], key="new_mood_ui", help="AIå½“å‰çš„å¿ƒæƒ…çŠ¶æ€ã€‚" #
        )
    with tabs[5]: #
        comps["intrusive_thought_block"] = st.text_input( #
            "Intrusive Thought",
            value=comps["intrusive_thought_block"], #
            key="new_intrusive_ui", #
            help="ä¸€ä¸ªçªç„¶äº§ç”Ÿçš„ã€å¯èƒ½ä¸ç›¸å…³çš„å¿µå¤´ã€‚", #
        )
    with tabs[6]: #
        comps["output_format_block"] = st.text_area( #
            "Output Format Requirement (JSON Schema)",
            value=comps["output_format_block"], #
            height=250, #
            key="new_output_format_ui", #
            help="ä¸¥æ ¼å®šä¹‰æ¨¡å‹è¾“å‡ºçš„JSONç»“æ„ã€‚", #
        )
    with tabs[7]: #
        comps["current_time_block"] = st.text_input( #
            "Current Time (ç”¨äº System Prompt)", value=comps["current_time_block"], key="new_time_ui", help="ä¼ é€’ç»™æ¨¡å‹çš„å½“å‰æ—¶é—´å­—ç¬¦ä¸²ï¼Œä¼šåŒ…å«åœ¨ System Prompt ä¸­ã€‚" # æ›´æ”¹æ ‡ç­¾å’Œå¸®åŠ©æ–‡æœ¬ #
        )


    st.session_state.new_ui_prompt_components = comps #

    st.markdown("---") #
    if st.button("ğŸ§  ç”Ÿæˆæ€è€ƒ (æ–°ç‰ˆUI)", type="primary", key="new_generate_thought_btn_ui"): #
        if st.session_state.core_initializer and st.session_state.core_initializer.main_consciousness_llm_client: #
            bot_name_val_new_ui = persona_cfg_new_ui.bot_name #

            # æ„å»º System Prompt (äººæ ¼é¢å…· + å½“å‰æ—¶é—´)
            final_system_prompt_for_llm_ui = f"å½“å‰æ—¶é—´ï¼š{comps['current_time_block']}\nä½ æ˜¯{bot_name_val_new_ui}ï¼›\n{comps['persona_block']}" #
            if persona_cfg_new_ui.profile and persona_cfg_new_ui.profile.strip(): # å¦‚æœ profile æœ‰å†…å®¹ä¸”ä¸åªæ˜¯ç©ºæ ¼
                 final_system_prompt_for_llm_ui += f"\n{persona_cfg_new_ui.profile}"


            # æ„å»º User Prompt (ä»»åŠ¡è§„åˆ™ + ä¸Šä¸‹æ–‡å†å² + æ€è€ƒæŒ‡å¼• + å¿ƒæƒ… + ä¾µå…¥æ€ç»´ + è¾“å‡ºæ ¼å¼è¦æ±‚)
            # ä½¿ç”¨ ThoughtPromptBuilder çš„æ¨¡æ¿ä½œä¸ºåŸºç¡€ï¼Œæ›¿æ¢å…¶ä¸­çš„å ä½ç¬¦
            # è¿™ç¡®ä¿äº†å³ä½¿æ¨¡æ¿ç»“æ„å¤æ‚ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½æ­£ç¡®å¡«å……
            try: #
                # ä» ThoughtPromptBuilder.PROMPT_TEMPLATE ä¸­æå– JSON Schema å‰åçš„éƒ¨åˆ†
                template_parts_ui = ThoughtPromptBuilder.PROMPT_TEMPLATE.split("ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š", 1) # <-- ä¿®æ”¹
                part1_before_json_schema_ui = template_parts_ui[0] + "ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š" #
                schema_and_suffix_parts_ui = template_parts_ui[1].split("è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š", 1) #
                part2_after_json_schema_ui = "è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š" + schema_and_suffix_parts_ui[1] #
                
                # ç”¨UIä¸­çš„è¾“å‡ºæ ¼å¼å—æ›¿æ¢åŸå§‹æ¨¡æ¿ä¸­çš„JSON Schemaéƒ¨åˆ†
                user_prompt_template_with_custom_schema = ( #
                    part1_before_json_schema_ui + f"\n{comps['output_format_block']}\n" + part2_after_json_schema_ui #
                )
            except IndexError: #
                st.warning("æ— æ³•æŒ‰é¢„æœŸåˆ†å‰²åŸå§‹Promptæ¨¡æ¿ä»¥æ’å…¥è‡ªå®šä¹‰JSON Schemaï¼Œå°†ä½¿ç”¨åŸå§‹æ¨¡æ¿ç»“æ„ï¼ˆè‡ªå®šä¹‰Schemaå¯èƒ½æœªç”Ÿæ•ˆï¼‰ã€‚") #
                user_prompt_template_with_custom_schema = ThoughtPromptBuilder.PROMPT_TEMPLATE # <-- ä¿®æ”¹

            # å¡«å…… User Prompt æ¨¡æ¿
            # æ³¨æ„ï¼šThoughtPromptBuilder.PROMPT_TEMPLATE ä¸­çš„ {current_time}, {bot_name}, {persona_description}, {persona_profile}
            # è¿™äº›å·²ç»ç§»åˆ° System Prompt ä¸­äº†ï¼Œæ‰€ä»¥åœ¨ format ç”¨æˆ· prompt æ—¶ï¼Œå®ƒä»¬ä¸åº”è¯¥å†è¢«æœŸæœ›ã€‚
            # æˆ‘ä»¬éœ€è¦ç¡®ä¿ user_prompt_template_with_custom_schema åªåŒ…å« User Prompt è¯¥æœ‰çš„å ä½ç¬¦ã€‚
            # ThoughtPromptBuilder.PROMPT_TEMPLATE æœ¬èº«å°±åªåŒ…å«è¯¥æœ‰çš„ User Prompt å ä½ç¬¦ã€‚
            
            # ä» comps ä¸­è·å–è¡ŒåŠ¨ç»“æœã€å¾…å¤„ç†è¡ŒåŠ¨çŠ¶æ€ç­‰ï¼Œå¦‚æœå®ƒä»¬æ˜¯åŠ¨æ€çš„
            # ä¸ºç®€åŒ–ï¼Œæš‚æ—¶ä½¿ç”¨ AIStateManager.INITIAL_STATE ä¸­çš„å€¼
            action_result_info_for_user_prompt = AIStateManager.INITIAL_STATE["action_result_info"] # <-- ä¿®æ”¹
            pending_action_status_for_user_prompt = AIStateManager.INITIAL_STATE["pending_action_status"] # <-- ä¿®æ”¹
            previous_thinking_for_user_prompt = AIStateManager.INITIAL_STATE["previous_thinking"] # å‡è®¾è¿™äº›ä¹Ÿæ˜¯ä»å†å²è®°å½•ä¸­æ¥ # <-- ä¿®æ”¹

            final_user_prompt_for_llm = user_prompt_template_with_custom_schema.format( #
                current_task_info=comps["task_rules_block"],  # è¿™æ˜¯UIä¸­çš„ "Task & Rules" #
                action_result_info=action_result_info_for_user_prompt, 
                pending_action_status=pending_action_status_for_user_prompt, 
                recent_contextual_information=comps["context_history_block"], # è¿™æ˜¯UIä¸­çš„ "Context & History" #
                master_chat_context="ä½ å’Œä¸»äººä¹‹é—´æ²¡æœ‰æœ€è¿‘çš„èŠå¤©è®°å½•ã€‚", # <-- æ–°å¢ master_chat_context
                previous_thinking=previous_thinking_for_user_prompt, 
                mood=f"ä½ ç°åœ¨çš„å¿ƒæƒ…å¤§æ¦‚æ˜¯ï¼š{comps['mood_block']}", # è¿™æ˜¯UIä¸­çš„ "Mood" #
                thinking_guidance=f"ç»è¿‡ä½ ä¸Šä¸€è½®çš„æ€è€ƒï¼Œä½ ç›®å‰æ‰“ç®—çš„æ€è€ƒæ–¹å‘æ˜¯ï¼š{comps['thinking_guidance_block']}", # è¿™æ˜¯UIä¸­çš„ "Thinking Guidance" #
                intrusive_thought=f"ä½ çªç„¶æœ‰ä¸€ä¸ªç¥å¥‡çš„å¿µå¤´ï¼š{comps['intrusive_thought_block']}" if comps["intrusive_thought_block"] else "", # è¿™æ˜¯UIä¸­çš„ "Intrusive Thought" #
            )


            with st.expander("å‘é€ç»™ä¸»æ„è¯†LLMçš„å®Œæ•´Prompt (æ–°ç‰ˆUIç»„åˆç»“æœ)", expanded=False): #
                st.text_area("System Prompt:", value=final_system_prompt_for_llm_ui, height=150, disabled=True, key="new_final_system_prompt_display_ui") #
                st.text_area("User Prompt:", value=final_user_prompt_for_llm, height=400, disabled=True, key="new_final_user_prompt_display_ui") #

            with st.spinner("æ–°ç‰ˆUIçš„LLMä¹Ÿåœ¨åŠªåŠ›æ€è€ƒä¸­...å–µ..."): #
                try:
                    response_data_new_ui = await st.session_state.core_initializer.main_consciousness_llm_client.make_llm_request( #
                        prompt=final_user_prompt_for_llm, #
                        system_prompt=final_system_prompt_for_llm_ui, #
                        is_stream=False #
                    )
                    
                    if response_data_new_ui.get("error"): #
                        st.error(f"LLMè°ƒç”¨å¤±è´¥: {response_data_new_ui.get('message')}") #
                        st.session_state.last_thought_json_new = None #
                        st.session_state.last_raw_response_new = f"LLM Error: {response_data_new_ui.get('message')}" #
                    else: #
                        raw_text_new_ui = response_data_new_ui.get("text", "") #
                        st.session_state.last_raw_response_new = raw_text_new_ui #
                        json_to_parse_new_ui = raw_text_new_ui.strip() #
                        if json_to_parse_new_ui.startswith("```json"): #
                            json_to_parse_new_ui = json_to_parse_new_ui[7:-3].strip() #
                        elif json_to_parse_new_ui.startswith("```"): #
                            json_to_parse_new_ui = json_to_parse_new_ui[3:-3].strip() #
                        try:
                            st.session_state.last_thought_json_new = json.loads(json_to_parse_new_ui) #
                        except json.JSONDecodeError as e: #
                            st.error(f"è§£æLLMçš„JSONå“åº”å¤±è´¥ (æ–°ç‰ˆUI): {e}") #
                            st.session_state.last_thought_json_new = None #
                except Exception as e_new_call: #
                    st.error(f"åœ¨æ–°ç‰ˆUIç”Ÿæˆæ€è€ƒæ—¶å‘ç”Ÿé”™è¯¯: {e_new_call}", icon="ğŸ’¥") #
                    st.exception(e_new_call) #
                    st.session_state.last_thought_json_new = None #
                    st.session_state.last_raw_response_new = str(e_new_call) #

        if "last_raw_response_new" in st.session_state: #
            with st.expander("ä¸»æ„è¯†LLMçš„åŸå§‹å›å¤ (æ–°ç‰ˆUI)", expanded=False): #
                st.text_area( #
                    "",
                    value=st.session_state.last_raw_response_new, #
                    height=200, #
                    disabled=True, #
                    key="new_raw_output_display_ui", #
                )

        if "last_thought_json_new" in st.session_state and st.session_state.last_thought_json_new: #
            st.subheader("ä¸»æ„è¯†LLMç»“æ„åŒ–è¾“å‡º (JSON) (æ–°ç‰ˆUI):") #
            st.json(st.session_state.last_thought_json_new, expanded=True) #
            if st.session_state.last_thought_json_new.get("action_to_take"): #
                st.success("è€¶ï¼LLMåˆæƒ³æäº‹æƒ…äº† (æ–°ç‰ˆUI)ï¼å¯ä»¥å»æµ‹åŠ¨ä½œå†³ç­–ã€‚", icon="ğŸ‰") #
            else: #
                st.info("LLMè¿™æ¬¡å¾ˆä¹–ï¼Œæ²¡å•¥è¡ŒåŠ¨æ„å›¾ (æ–°ç‰ˆUI)ã€‚", icon="ğŸ§¸") #


# --- ä¸»åº”ç”¨é€»è¾‘ ---
def main_app() -> None: #
    st.set_page_config(layout="wide", page_title="å°æ‡’çŒ« Prompt æµ‹è¯•ä¹å›­ V2.2") #
    initialize_session_state() #
    llm_configuration_sidebar() #

    page_options = {"åŸå§‹ç‰ˆæœ¬æµ‹è¯•å™¨ (æ—§)": show_original_ui, "ä»¿æˆªå›¾ç‰ˆæœ¬æµ‹è¯•å™¨ (æ–°)": show_new_ui} #

    with st.sidebar: #
        st.markdown("---") #
        st.title("é¡µé¢å¯¼èˆª NekoNaviâ„¢ V2.1") #
        chosen_page_title = st.radio( #
            "é€‰æ‹©ä¸€ä¸ªæµ‹è¯•é¡µé¢ç©ç©å§:",
            options=list(page_options.keys()), #
            key="page_selector_radio_ui", #
        )
    st.session_state.current_page = chosen_page_title #

    if st.session_state.current_page in page_options: #
        page_function = page_options[st.session_state.current_page]
        # å¯¹äºStreamlitï¼Œå¦‚æœé¡µé¢å‡½æ•°æ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ç”¨asyncio.runåŒ…è£…
        # æˆ–è€…è®©Streamlitæ”¯æŒå¼‚æ­¥å›è°ƒï¼ˆä½†å®ƒæœ¬èº«æ˜¯åŒæ­¥æ‰§è¡Œæ¨¡å‹çš„ï¼‰
        # ä¸ºäº†ç®€å•ï¼Œå¦‚æœpage_functionæ˜¯async defï¼Œåˆ™ä½¿ç”¨asyncio.run
        if asyncio.iscoroutinefunction(page_function):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(page_function())
            finally:
                loop.close()
        else: # å¦‚æœæ˜¯åŒæ­¥å‡½æ•°ï¼ˆè™½ç„¶è¿™é‡Œéƒ½æ˜¯async defï¼‰
            page_function()
    else: #
        # é»˜è®¤æ˜¾ç¤ºåŸå§‹UI
        default_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(default_loop)
        try:
            default_loop.run_until_complete(show_original_ui()) #
        finally:
            default_loop.close()


if __name__ == "__main__": #
    main_app() #
