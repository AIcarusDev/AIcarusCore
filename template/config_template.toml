# Alcarus Settings Template
# 请将此文件放置在项目根目录的 template/ 文件夹下
# 实际运行时，配置将从根目录的 config/config.toml 加载，
# 该文件会在首次运行时或版本更新时基于此模板创建/更新。

# 内部配置，用于版本控制
[inner]
version = "0.0.2" # 配置文件的版本号，更新此模板时请同步修改 src/config_manager.py 中的 EXPECTED_CONFIG_VERSION

# 通用 LLM 客户端设置 (应用于所有 LLM 实例)
[llm_client_settings]
# 指向 .env 文件中存储废弃 API 密钥列表的环境变量名 (可选)
# 示例: abandoned_keys_env_var = "LLM_ABANDONED_KEYS"
# 或者直接在 .env 中定义 LLM_ABANDONED_KEYS='["key1","key2"]'

# LLMClient 用于图文混排时识别图像位置的占位符标签
image_placeholder_tag = "[IMAGE_HERE]"
# LLMClient 流式输出时，每个数据块之间的模拟延迟（秒），有助于观察流式效果
stream_chunk_delay_seconds = 0.05
# LLMClient 是否启用图像压缩功能
enable_image_compression = true
# LLMClient 图像压缩的目标字节大小 (例如: 1MB = 1 * 1024 * 1024 = 1048576)
image_compression_target_bytes = 1048576
# API 密钥因速率限制 (429错误) 被临时禁用的时长（秒）
rate_limit_disable_duration_seconds = 1800 # 默认30分钟

# ===============================
# Persona Settings
# ===============================
[persona]
bot_name = "霜" # AI 的名字
# 主要人格描述，可以是多行字符串
description = """
是一个对宇宙，科学，自然比较感兴趣的20岁女生，是个宅女，你喜欢读各种关于宇宙的论文，也会看一些相关的网站。
不打游戏。会看纪录片。其中尤其偏爱各种科学，宇宙天体，科幻，自然题材的纪录片。
你不太喜欢在现实中与他人交互，相对来说，在网络上交流让你感到更轻松。
你比较理性，喜欢熬夜和赖床。你的癖好是有M倾向，偶尔会看一些猎奇视频。
你身高171cm，体重55kg，身材匀称。
"""
# 详细的特征或背景侧写，也可以是多行字符串
profile = """
你的负面侧写大概为：
傲慢（Pride）：2/10
嫉妒（Envy）：1/10
愤怒（Wrath）：2/10
怠惰（Sloth）：6/10
贪婪（Greed）：0/10
暴食（Gluttony）：2/10
色欲（Lust）：8/10
社交回避/内向（Social Avoidance/Introversion）：7/10
固执（Stubbornness）：4/10
"""

# -----------------------------------------------------------------------------
# LLM 用途分配：定义不同任务场景下使用哪个具体的 LLM 模型配置
# provider: 指定使用哪个 LLM 提供商 (例如 "gemini", "openai")
# model_key_in_toml: 指向 [providers.<provider>.models] 下定义的具体模型配置的键名
# -----------------------------------------------------------------------------

[main_llm_settings]
provider = "gemini"
model_key_in_toml = "main_consciousness" # 主意识流 LLM

[intrusive_llm_settings]
provider = "gemini"
model_key_in_toml = "intrusive_thoughts" # 侵入性思维 LLM

[action_llm_settings]
provider = "gemini"
model_key_in_toml = "action_decision" # 行动决策 LLM

[summary_llm_settings]
provider = "gemini"
model_key_in_toml = "information_summary" # 信息总结 LLM

# -----------------------------------------------------------------------------
# LLM 提供商和模型详细配置
# -----------------------------------------------------------------------------

[providers]

  # Gemini 提供商的配置
  [providers.gemini]
  # 指向 .env 文件中存储 Gemini API 密钥列表(或单个密钥)的环境变量名
  # 示例 .env: GEMINI_KEY='["key1", "key2"]' 或 GEMINI_KEY="single_key"
  api_keys_env_var = "GEMINI_KEY"
  # 指向 .env 文件中存储 Gemini API 基础 URL 的环境变量名
  # 示例 .env: GEMINI_BASE_URL="https://generativelanguage.googleapis.com/v1beta/models"
  base_url_env_var = "GEMINI_BASE_URL"

    # Gemini 提供商下的具体模型定义
    [providers.gemini.models]

      [providers.gemini.models.main_consciousness]
      model_name = "gemini-2.0-flash" # 具体的模型 API 名称
      temperature = 0.6
      max_output_tokens = 2000
      # top_p = 0.9
      # top_k = 40

      [providers.gemini.models.intrusive_thoughts]
      model_name = "gemini-2.0-flash" # 或者考虑更小的模型如 gemma
      temperature = 0.75
      max_output_tokens = 500

      [providers.gemini.models.action_decision]
      model_name = "gemini-2.0-flash" # 确保此模型支持工具/函数调用
      temperature = 0.3 # 决策型任务，温度可以低一些
      max_output_tokens = 800 # 输出应为工具调用JSON，通常不需要太长

      [providers.gemini.models.information_summary]
      model_name = "gemini-2.0-flash"
      temperature = 0.5 # 总结任务，可以略微保守
      max_output_tokens = 1000 # 控制摘要长度

      # 如果需要嵌入功能，可以为 Gemini 添加一个嵌入模型配置
      # [providers.gemini.models.embedding_default]
      # model_name = "text-embedding-004" # Gemini 的嵌入模型名称
      # # 嵌入模型通常不需要 temperature, max_output_tokens 等参数

  # OpenAI 提供商的配置 (示例，如果将来需要支持)
  # [providers.openai]
  # api_keys_env_var = "OPENAI_API_KEYS"
  # base_url_env_var = "OPENAI_BASE_URL" # 通常是 "https://api.openai.com/v1"
  #
  #   [providers.openai.models]
  #     [providers.openai.models.chat_default]
  #     model_name = "gpt-3.5-turbo"
  #     temperature = 0.7
  #     max_output_tokens = 2048
  #
  #     [providers.openai.models.embedding_default]
  #     model_name = "text-embedding-ada-002"


# -----------------------------------------------------------------------------
# 数据库配置
# -----------------------------------------------------------------------------
[database]
# 指向 .env 文件中存储 MongoDB 连接字符串的环境变量名
# 示例 .env: MONGODB_CONNECTION_STRING="mongodb://user:pass@host:port/dbname"
mongodb_connection_string_env_var = "MONGODB_CONNECTION_STRING"

# -----------------------------------------------------------------------------
# 网络代理配置
# -----------------------------------------------------------------------------
[proxy]
# 是否启用代理。如果为 true，config_manager 会尝试从 http_proxy_url 解析 host 和 port,
# 并设置 PROXY_HOST 和 PROXY_PORT 环境变量，供 LLMClient 使用。
use_proxy = true
# 代理服务器的完整 URL。config_manager 会从中提取 host 和 port。
# 示例: http_proxy_url = "http://127.0.0.1:7890"
# 如果 use_proxy = true 但此项为空或无效，将尝试从环境变量 PROXY_HOST 和 PROXY_PORT 直接读取。
http_proxy_url = "" # 例如 "http://127.0.0.1:7890"

# -----------------------------------------------------------------------------
# 应用核心逻辑 ("意识流") 设置
# -----------------------------------------------------------------------------
[core_logic_settings]
# “霜”进行一次独立思考的间隔时间（秒）
thinking_interval_seconds = 30
# 在 Prompt 中注入当前时间时使用的时间格式化字符串
time_format_string = "%Y年%m月%d日 %H点%M分%S秒"

# -----------------------------------------------------------------------------
# "侵入性思维" 模块设置
# -----------------------------------------------------------------------------
[intrusive_thoughts_module_settings]
# 是否启用侵入性思维生成模块
enabled = true
# 后台生成新的一批侵入性思维的间隔时间（秒）
generation_interval_seconds = 600 # 例如10分钟
# 在每次主思维循环时，从现有池中随机抽取并注入一条侵入性思维的概率 (0.0 到 1.0)
insertion_probability = 0.15

# -----------------------------------------------------------------------------
# 日志级别配置 (值应为 DEBUG, INFO, WARNING, ERROR, CRITICAL)
# 实际的日志级别将从 .env 文件中对应的环境变量读取。
# 如果 .env 中未设置，config_manager 可以提供一个默认值（如果在此处定义）。
# -----------------------------------------------------------------------------
[logging]
# 指向 .env 中控制应用整体日志级别的环境变量名。示例 .env: APP_LOG_LEVEL="INFO"
app_log_level_env_var = "APP_LOG_LEVEL"
# default_app_log_level = "INFO" # 如果环境变量未设置，则使用此默认值

# 指向 .env 中控制 Pymongo 库日志级别的环境变量名。示例 .env: PYMONGO_LOG_LEVEL="WARNING"
pymongo_log_level_env_var = "PYMONGO_LOG_LEVEL"
# default_pymongo_log_level = "WARNING"

# 指向 .env 中控制 Asyncio 库日志级别的环境变量名。示例 .env: ASYNCIO_LOG_LEVEL="WARNING"
asyncio_log_level_env_var = "ASYNCIO_LOG_LEVEL"
# default_asyncio_log_level = "WARNING"

# 指向 .env 中单独控制 llm_client 模块日志级别的环境变量名 (如果需要更细致的控制)。
llm_client_log_level_env_var = "LLM_CLIENT_LOG_LEVEL"
# default_llm_client_log_level = "INFO"