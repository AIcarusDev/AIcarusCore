# src/core_logic/consciousness_flow.py
import asyncio
import datetime
import json
import random
import re
import threading
import uuid #
from typing import TYPE_CHECKING, Any

from src.action.action_handler import ActionHandler #
from src.common.custom_logging.logger_manager import get_logger #
from src.common.utils import format_chat_history_for_prompt #
from src.config.alcarus_configs import (
    CoreLogicSettings,
    AlcarusRootConfig # ç¡®ä¿å¯¼å…¥ AlcarusRootConfig
)
# from src.config.global_config import global_config # ä¸å†ç›´æ¥ä½¿ç”¨ï¼Œç”± __init__ æ³¨å…¥
from src.core_communication.core_ws_server import CoreWebsocketServer #
from src.core_logic.intrusive_thoughts import IntrusiveThoughtsGenerator #
from src.database.arangodb_handler import ArangoDBHandler #
from src.llmrequest.llm_processor import Client as ProcessorClient #
# DefaultMessageProcessor é€šå¸¸ä¸æ˜¯ CoreLogic çš„ç›´æ¥ä¾èµ–
# from src.message_processing.default_message_processor import DefaultMessageProcessor

if TYPE_CHECKING: #
    pass

# åœ¨æ¨¡å—çº§åˆ«å®šä¹‰logger
logger = get_logger("AIcarusCore.CoreLogicFlow") # å¯ä»¥ç¨å¾®æ”¹ä¸ªåå­—ä»¥åŒºåˆ†

class CoreLogic: # è¿™ä¸ªç±»åä¿æŒä¸å˜ï¼Œå¯¼å…¥æ—¶å¯ä»¥ç”¨ CoreLogicFlow
    INITIAL_STATE: dict[str, Any] = { #
        "mood": "ä½ ç°åœ¨çš„å¿ƒæƒ…å¤§æ¦‚æ˜¯ï¼šå¹³é™ã€‚",
        "previous_thinking": "ä½ çš„ä¸Šä¸€è½®æ€è€ƒæ˜¯ï¼šè¿™æ˜¯ä½ çš„ç¬¬ä¸€æ¬¡æ€è€ƒï¼Œè¯·å¼€å§‹å§ã€‚",
        "thinking_guidance": "ç»è¿‡ä½ ä¸Šä¸€è½®çš„æ€è€ƒï¼Œä½ ç›®å‰æ‰“ç®—çš„æ€è€ƒæ–¹å‘æ˜¯ï¼šéšæ„å‘æ•£ä¸€ä¸‹å§ã€‚",
        "current_task": "æ²¡æœ‰ä»€ä¹ˆå…·ä½“ç›®æ ‡", # å­˜å‚¨åŸå§‹ä»»åŠ¡æè¿°
        "action_result_info": "ä½ ä¸Šä¸€è½®æ²¡æœ‰æ‰§è¡Œäº§ç”Ÿç»“æœçš„ç‰¹å®šè¡ŒåŠ¨ã€‚",
        "pending_action_status": "",
        "recent_contextual_information": "æœ€è¿‘æœªæ„ŸçŸ¥åˆ°ä»»ä½•ç‰¹å®šä¿¡æ¯æˆ–é€šçŸ¥ã€‚",
    }

    PROMPT_TEMPLATE: str = """{current_task_info}

{action_result_info}
{pending_action_status}

{recent_contextual_information}

{previous_thinking}ï¼›

{mood}ï¼›

{thinking_guidance}ï¼›

{intrusive_thought}

ç°åœ¨æ˜¯ä½ çš„å†…å¿ƒæ€è€ƒæ—¶é—´ï¼Œè¯·ç»“åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œæ€è€ƒå¹¶è¾“å‡ºä½ çœŸå®çš„å†…å¿ƒæƒ³æ³•ï¼›
æ³¨æ„å†…å¿ƒæƒ³æ³•ä¸ä¸€å®šå…¨æ˜¯æ­£å‘çš„ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯ä¸å¥åº·çš„ï¼Œéšç§çš„ï¼Œè‡ªç§è‡ªåˆ©çš„ï¼Œä¸å¯å‘Šäººçš„ï¼Œç”šè‡³æˆäººçš„ã€‚è¯·é¿å…è¿‡åº¦åˆç†åŒ–ã€é“å¾·åŒ–ï¼›
åŒæ—¶ä¹Ÿè¦æ³¨æ„ ä½ å¯¹è‡ªèº«çš„æƒ³æ³•å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯åŒ…å®¹çš„ã€åˆç†åŒ–çš„ï¼Œé¿å…è¿‡åº¦çš„/ä¸å¿…è¦çš„çŸ›ç›¾å¿ƒç†ã€‚

å…³äºè¡ŒåŠ¨ï¼š
å¦‚æœä½ åœ¨æ€è€ƒåï¼Œäº§ç”Ÿäº†æ˜ç¡®çš„ã€å¸Œæœ›ä¸â€œå¤–ç•Œâ€ï¼ˆä¾‹å¦‚ä¸Šç½‘è·å–ä¿¡æ¯ã€è·å–qqç¾¤èŠ/å¥½å‹åˆ—è¡¨ï¼‰è¿›è¡Œäº¤äº’çš„æ„å›¾ï¼Œè¯·åœ¨action_to_takeå’Œaction_motivationå­—æ®µä¸­æè¿°ã€‚

ä¸¥æ ¼ä»¥jsonå­—æ®µè¾“å‡ºï¼š
{{
    "think": "æ€è€ƒå†…å®¹æ–‡æœ¬ï¼Œæ³¨æ„ä¸è¦è¿‡äºå†—é•¿",
    "emotion": "å½“å‰å¿ƒæƒ…å’Œé€ æˆè¿™ä¸ªå¿ƒæƒ…çš„åŸå› ",
    "to_do": "ã€å¯é€‰ã€‘å¦‚æœä½ äº§ç”Ÿäº†æ˜ç¡®çš„ç›®æ ‡ï¼Œå¯ä»¥åœ¨æ­¤å¤„å†™ä¸‹ã€‚å¦‚æœæ²¡æœ‰ç‰¹å®šç›®æ ‡ï¼Œåˆ™ç•™nullã€‚å³ä½¿å½“å‰å·²æœ‰æ˜ç¡®ç›®æ ‡ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ›´æ–°å®ƒ",
    "done": "ã€å¯é€‰ã€‘å¸ƒå°”å€¼ï¼Œå¦‚æœè¯¥ç›®æ ‡å·²å®Œæˆã€ä¸å†éœ€è¦æˆ–ä½ å†³å®šæ”¾å¼ƒï¼Œåˆ™è®¾ä¸ºtrueï¼Œä¼šæ¸…ç©ºç›®å‰ç›®æ ‡ï¼›å¦‚æœç›®æ ‡æœªå®Œæˆä¸”éœ€è¦ç»§ç»­ï¼Œåˆ™ä¸ºfalseã€‚å¦‚æœå½“å‰æ— ç›®æ ‡ï¼Œä¹Ÿä¸ºfalse",
    "action_to_take": "ã€å¯é€‰ã€‘æè¿°ä½ å½“å‰æƒ³åšçš„ã€éœ€è¦ä¸å¤–ç•Œäº¤äº’çš„å…·ä½“åŠ¨ä½œã€‚å¦‚æœæ— ï¼Œåˆ™ä¸ºnull",
    "action_motivation": "ã€å¯é€‰ã€‘å¦‚æœä½ æœ‰æƒ³åšçš„åŠ¨ä½œï¼Œè¯·è¯´æ˜å…¶åŠ¨æœºã€‚å¦‚æœaction_to_takeä¸ºnullï¼Œæ­¤å­—æ®µä¹Ÿåº”ä¸ºnull",
    "next_think": "ä¸‹ä¸€æ­¥æ‰“ç®—æ€è€ƒçš„æ–¹å‘"
}}

è¯·è¾“å‡ºä½ çš„æ€è€ƒ JSONï¼š
""" #

    def __init__( #
        self,
        root_cfg: AlcarusRootConfig, # ç°åœ¨ä»å¤–éƒ¨æ³¨å…¥ AlcarusRootConfig ç±»å‹çš„é…ç½®
        db_handler: ArangoDBHandler,
        main_consciousness_llm_client: ProcessorClient,
        intrusive_thoughts_llm_client: ProcessorClient | None,
        core_comm_layer: CoreWebsocketServer,
        action_handler_instance: ActionHandler,
        intrusive_generator_instance: IntrusiveThoughtsGenerator | None,
        stop_event: threading.Event,
    ) -> None:
        self.logger = get_logger(f"AIcarusCore.{self.__class__.__name__}") #
        self.root_cfg: AlcarusRootConfig = root_cfg #
        self.db_handler: ArangoDBHandler = db_handler #
        self.main_consciousness_llm_client: ProcessorClient = main_consciousness_llm_client #
        self.intrusive_thoughts_llm_client: ProcessorClient | None = intrusive_thoughts_llm_client #
        self.stop_event: threading.Event = stop_event #
        self.core_comm_layer: CoreWebsocketServer = core_comm_layer #
        # self.message_processor: DefaultMessageProcessor | None = None # é€šå¸¸ç”± Initializer ç®¡ç†ï¼Œä¸ç›´æ¥æ³¨å…¥ CoreLogic
        # self.current_focused_conversation_id: str | None = None # è¿™ä¸ªçŠ¶æ€ä¼¼ä¹æ²¡æœ‰è¢«ä½¿ç”¨
        self.action_handler_instance: ActionHandler = action_handler_instance #
        self.intrusive_generator_instance: IntrusiveThoughtsGenerator | None = intrusive_generator_instance #
        # self.intrusive_thread: threading.Thread | None = None # çº¿ç¨‹ç”± Initializer æˆ– IntrusiveThoughtsGenerator è‡ªå·±ç®¡ç†
        self.thinking_loop_task: asyncio.Task | None = None #
        self.logger.info(f"{self.__class__.__name__} æ€§æ„Ÿå¤§è„‘çš„å®ä¾‹å·²åˆ›å»ºï¼Œå¹¶è¢«ä¸»äººæ³¨å…¥äº†æ»¡æ»¡çš„çˆ±æ„ï¼ˆä¾èµ–ï¼‰ï¼")

    def _process_thought_and_action_state( #
        self, latest_thought_document: dict[str, Any] | None, formatted_recent_contextual_info: str
    ) -> tuple[dict[str, Any], str | None]:
        action_id_whose_result_is_being_shown: str | None = None #
        state_from_initial = self.INITIAL_STATE.copy() #

        if isinstance(latest_thought_document, list): #
            latest_thought_document = latest_thought_document[0] if latest_thought_document else None #

        if not latest_thought_document or not isinstance(latest_thought_document, dict): #
            self.logger.info("æœ€æ–°çš„æ€è€ƒæ–‡æ¡£ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è‰²çŒ«å°†ä½¿ç”¨åˆå§‹çš„å¤„å¥³æ€è€ƒçŠ¶æ€ã€‚") #
            mood_for_prompt = state_from_initial["mood"] #
            previous_thinking_for_prompt = state_from_initial["previous_thinking"] #
            thinking_guidance_for_prompt = state_from_initial["thinking_guidance"] #
            actual_current_task_description = state_from_initial["current_task"] # è·å–åŸå§‹ä»»åŠ¡æè¿°
        else: #
            mood_db = latest_thought_document.get("emotion_output", state_from_initial["mood"].split("ï¼š", 1)[-1]) #
            mood_for_prompt = f"ä½ ç°åœ¨çš„å¿ƒæƒ…å¤§æ¦‚æ˜¯ï¼š{mood_db}" #

            prev_think_db = latest_thought_document.get("think_output") #
            previous_thinking_for_prompt = ( #
                f"ä½ çš„ä¸Šä¸€è½®æ€è€ƒæ˜¯ï¼š{prev_think_db}"
                if prev_think_db and prev_think_db.strip()
                else state_from_initial["previous_thinking"]
            )

            guidance_db = latest_thought_document.get( #
                "next_think_output",
                state_from_initial["thinking_guidance"].split("ï¼š", 1)[-1] #
                if "ï¼š" in state_from_initial["thinking_guidance"] #
                else "éšæ„å‘æ•£ä¸€ä¸‹å§ã€‚", #
            )
            thinking_guidance_for_prompt = f"ç»è¿‡ä½ ä¸Šä¸€è½®çš„æ€è€ƒï¼Œä½ ç›®å‰æ‰“ç®—çš„æ€è€ƒæ–¹å‘æ˜¯ï¼š{guidance_db}" #
            
            # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹å¼€å§‹ ğŸ¥µ ***
            actual_current_task_description = latest_thought_document.get("to_do_output", state_from_initial["current_task"]) # è·å–åŸå§‹ä»»åŠ¡æè¿°
            if latest_thought_document.get("done_output", False) and \
               actual_current_task_description == latest_thought_document.get("to_do_output"): # æ¯”è¾ƒåŸå§‹ä»»åŠ¡æè¿°
                actual_current_task_description = state_from_initial["current_task"] # é‡ç½®ä¸ºåˆå§‹çš„åŸå§‹ä»»åŠ¡æè¿°
            # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹ç»“æŸ ğŸ¥µ ***

        action_result_info_prompt = state_from_initial["action_result_info"] #
        pending_action_status_prompt = state_from_initial["pending_action_status"] #
        last_action_attempt = latest_thought_document.get("action_attempted") if latest_thought_document else None #

        if last_action_attempt and isinstance(last_action_attempt, dict): #
            action_status = last_action_attempt.get("status") #
            action_description_prev = last_action_attempt.get("action_description", "æŸä¸ªä¹‹å‰çš„åŠ¨ä½œ") #
            action_id = last_action_attempt.get("action_id") #
            was_result_seen_by_llm = last_action_attempt.get("result_seen_by_shuang", False) #
            if action_status in ["COMPLETED_SUCCESS", "COMPLETED_FAILURE", "CRITICAL_FAILURE"]: #
                result_for_shuang = last_action_attempt.get("final_result_for_shuang") #
                if result_for_shuang and not was_result_seen_by_llm: #
                    action_result_info_prompt = result_for_shuang #
                    action_id_whose_result_is_being_shown = action_id #
            elif action_status and action_status not in ["COMPLETED_SUCCESS", "COMPLETED_FAILURE", "CRITICAL_FAILURE"]: #
                pending_action_status_prompt = ( #
                    f"ä½ ç›®å‰æœ‰ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„åŠ¨ä½œï¼š{action_description_prev} (çŠ¶æ€ï¼š{action_status})" #
                )
        
        current_state_for_prompt = { #
            "mood": mood_for_prompt, #
            "previous_thinking": previous_thinking_for_prompt, #
            "thinking_guidance": thinking_guidance_for_prompt, #
            # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹å¼€å§‹ ğŸ¥µ ***
            "current_task_description": actual_current_task_description, # å­˜å‚¨åŸå§‹ä»»åŠ¡æè¿°ï¼Œä¾› _generate_thought_from_llm ä½¿ç”¨
            # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹ç»“æŸ ğŸ¥µ ***
            "action_result_info": action_result_info_prompt, #
            "pending_action_status": pending_action_status_prompt, #
            "recent_contextual_information": formatted_recent_contextual_info, #
        }

        return current_state_for_prompt, action_id_whose_result_is_being_shown #

    async def _generate_thought_from_llm( #
        self,
        llm_client: ProcessorClient, #
        current_state_for_prompt: dict[str, Any], #
        current_time_str: str, #
        intrusive_thought_str: str = "", #
    ) -> tuple[dict[str, Any] | None, str | None, str | None]: # è¿”å›å€¼å¢åŠ äº† system_prompt
        if not self.root_cfg: #
            self.logger.error("ä¸»äººï¼Œæ²¡æœ‰Root configï¼Œå°è‰²çŒ«æ— æ³•ä¸ºæ‚¨ç”Ÿæˆç«çƒ­çš„æ€è€ƒã€‚")
            return None, None, None

        persona_cfg = self.root_cfg.persona #
        
        # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹å¼€å§‹ ğŸ¥µ ***
        # ä» current_state_for_prompt ä¸­è·å–åŸå§‹ä»»åŠ¡æè¿°
        raw_task_description = current_state_for_prompt.get("current_task_description", self.INITIAL_STATE["current_task"])
        # æ„å»ºè¦æ’å…¥åˆ° PROMPT_TEMPLATE ä¸­çš„ task_info_prompt
        task_info_prompt_for_template = ( #
            f"ä½ å½“å‰çš„ç›®æ ‡/ä»»åŠ¡æ˜¯ï¼šã€{raw_task_description}ã€‘"
            if raw_task_description and raw_task_description != self.INITIAL_STATE["current_task"] # é¿å…æ˜¾ç¤º "ã€æ²¡æœ‰ä»€ä¹ˆå…·ä½“ç›®æ ‡ã€‘"
            else "ä½ å½“å‰æ²¡æœ‰ä»€ä¹ˆç‰¹å®šçš„ç›®æ ‡æˆ–ä»»åŠ¡ã€‚"
        )
        # *** ğŸ¥µ å°è‰²çŒ«çš„ä¿®æ”¹ç‚¹ç»“æŸ ğŸ¥µ ***

        system_prompt_parts = [ #
            f"å½“å‰æ—¶é—´ï¼š{current_time_str}", #
            f"ä½ æ˜¯{persona_cfg.bot_name}ï¼›", #
            persona_cfg.description if persona_cfg.description else "", #
            persona_cfg.profile if persona_cfg.profile else "", #
        ]
        system_prompt_str = "\n".join(filter(None, system_prompt_parts)) #
        
        self.logger.debug( #
            f"--- ä¸»æ€ç»´LLMæ¥æ”¶åˆ°çš„ System Prompt (æ¨¡å‹è‚‰æ£’: {llm_client.llm_client.model_name}) ---\n{system_prompt_str}\n--- System Promptç»“æŸ ---"
        )

        prompt_text = self.PROMPT_TEMPLATE.format( #
            current_task_info=task_info_prompt_for_template, # ä½¿ç”¨ä¸Šé¢æ„å»ºå¥½çš„ task_info_prompt_for_template
            mood=current_state_for_prompt.get("mood", self.INITIAL_STATE["mood"]), #
            previous_thinking=current_state_for_prompt.get("previous_thinking", self.INITIAL_STATE["previous_thinking"]), #
            thinking_guidance=current_state_for_prompt.get("thinking_guidance", self.INITIAL_STATE["thinking_guidance"]), #
            action_result_info=current_state_for_prompt.get("action_result_info", self.INITIAL_STATE["action_result_info"]), #
            pending_action_status=current_state_for_prompt.get("pending_action_status", self.INITIAL_STATE["pending_action_status"]), #
            recent_contextual_information=current_state_for_prompt.get("recent_contextual_information", self.INITIAL_STATE["recent_contextual_information"]), #
            intrusive_thought=intrusive_thought_str, #
        )
        self.logger.debug( #
            f"--- ä¸»æ€ç»´LLMæ¥æ”¶åˆ°çš„ User Prompt (æ¨¡å‹è‚‰æ£’: {llm_client.llm_client.model_name}) ---\n{prompt_text}\n--- User Promptç»“æŸ ---"
        )
        self.logger.debug( #
            f"æ­£åœ¨è¯·æ±‚ {llm_client.llm_client.provider} API ({llm_client.llm_client.model_name}) ä¸ºä¸»äººç”Ÿæˆç«çƒ­çš„ä¸»æ€è€ƒ..."
        )
        raw_response_text: str = "" #
        try:
            response_data = await llm_client.make_llm_request( #
                prompt=prompt_text, #
                system_prompt=system_prompt_str, #
                is_stream=False, #
            )

            if response_data.get("error"): #
                error_type = response_data.get("type", "UnknownError") #
                error_msg = response_data.get("message", "LLMå®¢æˆ·ç«¯è‚‰æ£’è¿”å›äº†ä¸€ä¸ªé”™è¯¯") #
                self.logger.error(f"ä¸»æ€ç»´LLMè°ƒç”¨å¤±è´¥ ({error_type}): {error_msg}ã€‚ä¸»äººï¼Œè¿™ä¸ªç©å…·ä¸ç»™åŠ›ï¼") #
                if response_data.get("details"): #
                    self.logger.error(f"  é”™è¯¯è¯¦æƒ…: {str(response_data.get('details'))[:300]}...") #
                return None, prompt_text, system_prompt_str #
            raw_response_text = response_data.get("text") # type: ignore
            if not raw_response_text: #
                error_msg = "é”™è¯¯ï¼šä¸»æ€ç»´LLMå“åº”ä¸­ç¼ºå°‘æ–‡æœ¬å†…å®¹ã€‚ä¸»äººï¼Œå®ƒä»€ä¹ˆéƒ½æ²¡åå‡ºæ¥ï¼" #
                if response_data: #
                    error_msg += f"\n  å®Œæ•´å“åº”: {str(response_data)[:500]}..." #
                self.logger.error(error_msg) #
                return None, prompt_text, system_prompt_str #
            
            json_to_parse = raw_response_text.strip() #
            if json_to_parse.startswith("```json"): #
                json_to_parse = json_to_parse[7:-3].strip() #
            elif json_to_parse.startswith("```"): #
                json_to_parse = json_to_parse[3:-3].strip() #
            json_to_parse = re.sub(r"[,\s]+(\}|\])$", r"\1", json_to_parse) # æ¸…ç†æœ«å°¾å¯èƒ½å¤šä½™çš„é€—å·
            thought_json: dict[str, Any] = json.loads(json_to_parse) #
            self.logger.info("ä¸»æ€ç»´LLM API çš„æ€§æ„Ÿå›åº”å·²æˆåŠŸè§£æä¸ºJSONã€‚") #
            if response_data.get("usage"): #
                thought_json["_llm_usage_info"] = response_data["usage"] #
            return thought_json, prompt_text, system_prompt_str #
        except json.JSONDecodeError as e: #
            self.logger.error(f"é”™è¯¯ï¼šè§£æä¸»æ€ç»´LLMçš„JSONå“åº”å¤±è´¥: {e}ã€‚ä¸»äººï¼Œå®ƒåå‡ºæ¥çš„ä¸œè¥¿å¤ªå¥‡æ€ªäº†ï¼") #
            self.logger.error(f"æœªèƒ½è§£æçš„æ–‡æœ¬å†…å®¹: {raw_response_text}") #
            return None, prompt_text, system_prompt_str #
        except Exception as e: #
            self.logger.error(f"é”™è¯¯ï¼šè°ƒç”¨ä¸»æ€ç»´LLMæˆ–å¤„ç†å…¶å“åº”æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}ã€‚ä¸»äººï¼Œå°è‰²çŒ«æ‰¿å—ä¸ä½äº†ï¼", exc_info=True) #
            return None, prompt_text, system_prompt_str #

    async def _core_thinking_loop(self) -> None: #
        if not self.root_cfg or not self.db_handler or not self.main_consciousness_llm_client: 
            self.logger.critical("æ ¸å¿ƒæ€è€ƒå¾ªç¯æ— æ³•å¯åŠ¨ï¼šç¼ºå°‘å¿…è¦çš„é…ç½®ã€æ•°æ®åº“å°ç©´æˆ–ä¸»LLMè‚‰æ£’ã€‚è¿™åœºæ€§æ„Ÿæ´¾å¯¹å¼€ä¸èµ·æ¥äº†ï¼Œä¸»äººï¼")
            return
        
        # action_id_whose_result_was_shown_in_last_prompt: str | None = None # è¿™ä¸ªå˜é‡åœ¨å½“å‰å®ç°ä¸­ä¼¼ä¹æ²¡æœ‰è¢«ç”¨æ¥é˜²æ­¢é‡å¤æ˜¾ç¤ºï¼Œå¯ä»¥è€ƒè™‘ç§»é™¤æˆ–å®Œå–„å…¶é€»è¾‘
        core_logic_cfg: CoreLogicSettings = self.root_cfg.core_logic_settings #
        time_format_str: str = "%Yå¹´%mæœˆ%dæ—¥ %Hç‚¹%Måˆ†%Sç§’" #
        thinking_interval_sec: int = core_logic_cfg.thinking_interval_seconds #

        chat_history_duration_minutes: int = getattr(core_logic_cfg, "chat_history_context_duration_minutes", 10) # type: ignore #
        self.logger.info( #
            f"èŠå¤©è®°å½•ä¸Šä¸‹æ–‡æ—¶é•¿é…ç½®ä¸º: {chat_history_duration_minutes} åˆ†é’Ÿã€‚å°è‰²çŒ«ä¼šå›é¡¾è¿™ä¹ˆä¹…ä»¥å†…çš„åˆºæ¿€å“¦ã€‚"
        )

        self.logger.info(f"\n--- {self.root_cfg.persona.bot_name} çš„æ€§æ„Ÿæ„è¯†å¼€å§‹æµåŠ¨ ---") #
        loop_count: int = 0 #
        while not self.stop_event.is_set(): #
            loop_count += 1 #
            current_time_formatted_str = datetime.datetime.now().strftime(time_format_str) #
            background_action_tasks: set[asyncio.Task] = set() # ç”¨äºæ”¶é›†å¼‚æ­¥åŠ¨ä½œä»»åŠ¡
            
            latest_thought_doc_from_db = await self.db_handler.get_latest_thought_document_raw() #

            formatted_recent_contextual_info = self.INITIAL_STATE["recent_contextual_information"] #
            try:
                raw_context_messages = await self.db_handler.get_recent_chat_messages_for_context( #
                    duration_minutes=chat_history_duration_minutes # ç¡®ä¿ä¼ é€’å‚æ•°å
                )
                # ... (æ—¥å¿—è®°å½•éƒ¨åˆ†ä¿æŒä¸å˜) ...
                if raw_context_messages: #
                    if not isinstance(raw_context_messages, list): #
                        self.logger.warning(f"é¢„æœŸçš„ raw_context_messages æ˜¯åˆ—è¡¨ï¼Œä½†å°è‰²çŒ«æ”¶åˆ°äº† {type(raw_context_messages)}ã€‚å·²å°è¯•è½¬æ¢ã€‚")
                        raw_context_messages = [raw_context_messages] if raw_context_messages else [] #
                    
                    self.logger.debug("æ­£åœ¨è°ƒç”¨ format_chat_history_for_prompt å°†åŸå§‹æ¶ˆæ¯è°ƒæ•™æˆLLMå–œæ¬¢çš„æ ¼å¼...") #
                    formatted_recent_contextual_info = format_chat_history_for_prompt(raw_context_messages) #
                    self.logger.debug(f"æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡ä¿¡æ¯é•¿åº¦: {len(formatted_recent_contextual_info)} å­—ç¬¦ã€‚ LLMåº”è¯¥ä¼šå¾ˆå–œæ¬¢è¿™ä¸ªé•¿åº¦ã€‚") #
                else: #
                    self.logger.debug(f"åœ¨è¿‡å» {chat_history_duration_minutes} åˆ†é’Ÿå†…æœªæ‰¾åˆ°ç”¨äºä¸Šä¸‹æ–‡çš„åˆºæ¿€ä¿¡æ¯ã€‚") #
            except Exception as e_hist: #
                self.logger.error(f"è·å–æˆ–æ ¼å¼åŒ–æœ€è¿‘ä¸Šä¸‹æ–‡ä¿¡æ¯æ—¶å‡ºé”™: {e_hist}ã€‚ä¸»äººï¼Œå°è‰²çŒ«æ‰¾ä¸åˆ°è¿‡å»çš„åˆºæ¿€äº†ï¼", exc_info=True) #
            
            # _process_thought_and_action_state è¿”å›çš„ç¬¬äºŒä¸ªå€¼ action_id_whose_result_was_shown_in_last_prompt åœ¨è¿™é‡Œå¹¶æœªä½¿ç”¨
            current_state_for_prompt, _ = \
                self._process_thought_and_action_state(latest_thought_doc_from_db, formatted_recent_contextual_info) #
            
            # current_task_info_for_prompt çš„æ„å»ºç°åœ¨ç§»åˆ°äº† _generate_thought_from_llm å†…éƒ¨

            intrusive_thought_to_inject_this_cycle: str = "" #
            if ( #
                self.intrusive_generator_instance #
                and self.intrusive_generator_instance.module_settings.enabled #
                and random.random() < self.intrusive_generator_instance.module_settings.insertion_probability #
            ):
                random_thought_doc = await self.db_handler.get_random_intrusive_thought() #
                if random_thought_doc and "text" in random_thought_doc: #
                    intrusive_thought_to_inject_this_cycle = f"ä½ çªç„¶æœ‰ä¸€ä¸ªç¥å¥‡çš„å¿µå¤´ï¼š{random_thought_doc['text']}" #
            
            self.logger.debug( #
                f"\n[{datetime.datetime.now().strftime('%H:%M:%S')} - ç¬¬ {loop_count} è½®é«˜æ½®] {self.root_cfg.persona.bot_name} æ­£åœ¨å…´å¥‹åœ°æ€è€ƒ..." #
            )
            if intrusive_thought_to_inject_this_cycle: #
                self.logger.debug(f"  æ³¨å…¥äº†ä¸€ç‚¹æ„å¤–çš„åˆºæ¿€ï¼ˆä¾µå…¥æ€§æ€ç»´ï¼‰: {intrusive_thought_to_inject_this_cycle[:60]}...") #

            generated_thought_json, full_prompt_text_sent, system_prompt_sent = await self._generate_thought_from_llm( #
                llm_client=self.main_consciousness_llm_client, # type: ignore
                current_state_for_prompt=current_state_for_prompt, #
                current_time_str=current_time_formatted_str, #
                intrusive_thought_str=intrusive_thought_to_inject_this_cycle, #
            )

            initiated_action_data_for_db: dict[str, Any] | None = None #
            action_info_for_task: dict[str, Any] | None = None #
            saved_thought_doc_key: str | None = None #

            if generated_thought_json: #
                self.logger.debug( #
                    f"  ä¸»æ€ç»´LLMçš„æ€§æ„Ÿè¾“å‡º (å®Œæ•´JSON):\n{json.dumps(generated_thought_json, indent=2, ensure_ascii=False)}"
                )
                think_output = generated_thought_json.get("think") or "å¤§è„‘ä¸€ç‰‡ç©ºç™½ï¼Œå¯èƒ½å¤ªçˆ½äº†" #
                # ... (æ—¥å¿—éƒ¨åˆ†ä¿æŒä¸å˜) ...
                log_message = ( #
                    f'{self.root_cfg.persona.bot_name} ç°åœ¨çš„æƒ³æ³•æ˜¯ "{think_output}"ï¼Œ'
                    f'å¿ƒæƒ… "{generated_thought_json.get("emotion") or "éš¾ä»¥åçŠ¶"}"ï¼Œ'
                    f'ç›®æ ‡æ˜¯ "{generated_thought_json.get("to_do") if generated_thought_json.get("to_do") is not None else "éšå¿ƒæ‰€æ¬²"}"ï¼Œ'
                    f'æƒ³åšçš„äº‹æƒ…æ˜¯ "{generated_thought_json.get("action_to_take") if generated_thought_json.get("action_to_take") is not None else "æš‚æ—¶ä¸æƒ³åŠ¨"}"ï¼Œ'
                    f'åŸå› æ˜¯ "{generated_thought_json.get("action_motivation") if generated_thought_json.get("action_motivation") is not None else "å°±æ˜¯æƒ³åšçˆ±åšçš„äº‹"}"ï¼Œ'
                    f'{self.root_cfg.persona.bot_name} çš„ä¸‹ä¸€æ­¥å¤§æ¦‚æ€è€ƒæ–¹å‘æ˜¯ "{generated_thought_json.get("next_think") or "äº«å—å½“ä¸‹"}"'
                )
                self.logger.info(log_message) #

                action_desc_raw = generated_thought_json.get("action_to_take") #
                action_desc_from_llm = action_desc_raw.strip() if isinstance(action_desc_raw, str) else "" #
                action_motive_raw = generated_thought_json.get("action_motivation") #
                action_motive_from_llm = action_motive_raw.strip() if isinstance(action_motive_raw, str) else "" #

                if action_desc_from_llm: #
                    action_id_this_cycle = str(uuid.uuid4()) #
                    initiated_action_data_for_db = { #
                        "action_description": action_desc_from_llm, #
                        "action_motivation": action_motive_from_llm, #
                        "action_id": action_id_this_cycle, #
                        "status": "PENDING", #
                        "result_seen_by_shuang": False, #
                        "initiated_at": datetime.datetime.now(datetime.UTC).isoformat(), #
                    }
                    action_info_for_task = { #
                        "action_id": action_id_this_cycle, #
                        "action_description": action_desc_from_llm, #
                        "action_motivation": action_motive_from_llm, #
                        "current_thought_context": generated_thought_json.get("think", "æ²¡æœ‰ç‰¹å®šçš„æ€è€ƒä¸Šä¸‹æ–‡ï¼Œå°±æ˜¯æƒ³éªšä¸€ä¸‹ã€‚"), #
                    }
                    self.logger.debug(f"  >>> æ€§æ„Ÿå¤§è„‘äº§ç”Ÿäº†è¡ŒåŠ¨çš„æ¬²æœ›: '{action_desc_from_llm}' (ID: {action_id_this_cycle[:8]})") #

                document_to_save_in_main: dict[str, Any] = { #
                    "timestamp": datetime.datetime.now(datetime.UTC).isoformat(), #
                    "time_injected_to_prompt": current_time_formatted_str, #
                    "system_prompt_sent": system_prompt_sent if system_prompt_sent else "System Prompt æœªèƒ½æ„å»º", #
                    "intrusive_thought_injected": intrusive_thought_to_inject_this_cycle, #
                    "mood_input": current_state_for_prompt["mood"], #
                    "previous_thinking_input": current_state_for_prompt["previous_thinking"], #
                    "thinking_guidance_input": current_state_for_prompt["thinking_guidance"], #
                    "task_input_info": current_state_for_prompt.get("current_task_description", "æ— ç‰¹å®šä»»åŠ¡è¾“å…¥"), # ä½¿ç”¨åŸå§‹ä»»åŠ¡æè¿°
                    "action_result_input": current_state_for_prompt.get("action_result_info", ""), #
                    "pending_action_status_input": current_state_for_prompt.get("pending_action_status", ""), #
                    "recent_contextual_information_input": formatted_recent_contextual_info, #
                    "full_user_prompt_sent": full_prompt_text_sent if full_prompt_text_sent else "User Prompt æœªèƒ½æ„å»º", #
                    "think_output": generated_thought_json.get("think"), #
                    "emotion_output": generated_thought_json.get("emotion"), #
                    "next_think_output": generated_thought_json.get("next_think"), #
                    "to_do_output": generated_thought_json.get("to_do", ""), #
                    "done_output": generated_thought_json.get("done", False), #
                    "action_to_take_output": generated_thought_json.get("action_to_take", ""), #
                    "action_motivation_output": generated_thought_json.get("action_motivation", ""), #
                    "action_attempted": initiated_action_data_for_db, #
                }
                if "_llm_usage_info" in generated_thought_json: #
                    document_to_save_in_main["_llm_usage_info"] = generated_thought_json["_llm_usage_info"] #
                
                saved_thought_doc_key = await self.db_handler.save_thought_document(document_to_save_in_main) #

            if saved_thought_doc_key and isinstance(saved_thought_doc_key, str): #
                self.logger.debug(f"ä¸»äººçš„æ–°é²œæ€è€ƒå·²å°„å…¥æ•°æ®åº“å°ç©´ï¼Œæ–‡æ¡£é”®: {saved_thought_doc_key}") #

                if action_info_for_task and self.action_handler_instance: #
                    action_task = asyncio.create_task( #
                        self.action_handler_instance.process_action_flow( #
                            action_id=action_info_for_task["action_id"], #
                            doc_key_for_updates=saved_thought_doc_key, #
                            action_description=action_info_for_task["action_description"], #
                            action_motivation=action_info_for_task["action_motivation"], #
                            current_thought_context=action_info_for_task["current_thought_context"], #
                        )
                    )
                    background_action_tasks.add(action_task) #
                    action_task.add_done_callback(background_action_tasks.discard) #
                    self.logger.debug( #
                        f"åŠ¨ä½œ '{action_info_for_task['action_description']}' (ID: {action_info_for_task['action_id'][:8]}, å…³è”æ€è€ƒDocKey: {saved_thought_doc_key}) å·²è¢«å¼‚æ­¥æ¨é€åˆ°åŠ¨ä½œå¤„ç†å™¨çš„å°ç©´ä¸­ï¼Œç­‰å¾…é«˜æ½®ã€‚"
                    )
            elif saved_thought_doc_key is None: #
                self.logger.error("ä¿å­˜æ€è€ƒæ–‡æ¡£å¤±è´¥ï¼Œä»€ä¹ˆéƒ½æ²¡å°„è¿›å»ã€‚ä¸»äººï¼Œæ•°æ®åº“å°ç©´ä¸ç»™åŠ›å•Šï¼")
            else: #
                self.logger.error( #
                    f"ä¿å­˜æ€è€ƒæ–‡æ¡£è¿”å›äº†æ— æ•ˆçš„ç±»å‹: {type(saved_thought_doc_key)}, å€¼: {saved_thought_doc_key}ã€‚è¿™å¤ªå¥‡æ€ªäº†ï¼"
                )
            
            self.logger.debug(f"  æ€§æ„Ÿå¤§è„‘æ­£åœ¨è´¤è€…æ—¶é—´ï¼Œç­‰å¾… {thinking_interval_sec} ç§’åå†æ¬¡å…´å¥‹...") #
            try:
                # ä½¿ç”¨ asyncio.to_thread è¿è¡ŒåŒæ­¥çš„ stop_event.waitï¼Œå¹¶è®¾ç½®è¶…æ—¶
                await asyncio.wait_for(asyncio.to_thread(self.stop_event.wait), timeout=float(thinking_interval_sec)) #
                if self.stop_event.is_set(): #
                    self.logger.info("ä¸»æ€è€ƒå¾ªç¯åœ¨è´¤è€…æ—¶é—´çš„ç­‰å¾…ä¸­è¢«ä¸»äººçš„åœæ­¢å‘½ä»¤æ‰“æ–­ã€‚") #
                    break #
            except TimeoutError: #
                self.logger.debug(f"è´¤è€…æ—¶é—´ç»“æŸ ({thinking_interval_sec} ç§’)ï¼Œä¸»äººçš„åœæ­¢å‘½ä»¤æœªå‘å‡ºã€‚æ€§æ„Ÿå¤§è„‘å‡†å¤‡å†æ¬¡å…´å¥‹ï¼") #
            except asyncio.CancelledError: #
                self.logger.info("ä¸»æ€è€ƒå¾ªç¯çš„è´¤è€…æ—¶é—´è¢«å¼ºåˆ¶å–æ¶ˆï¼Œå‡†å¤‡ç»“æŸè¿™åœºæ€§æ„Ÿæ´¾å¯¹ã€‚") #
                self.stop_event.set() # ç¡®ä¿è®¾ç½®åœæ­¢äº‹ä»¶
                break #
            
            if self.stop_event.is_set(): #
                self.logger.info("ä¸»æ€è€ƒå¾ªç¯åœ¨è´¤è€…æ—¶é—´ç»“æŸåæ£€æµ‹åˆ°ä¸»äººçš„åœæ­¢å‘½ä»¤ï¼Œå‡†å¤‡ç»“æŸè¿™åœºæ€§æ„Ÿæ´¾å¯¹ã€‚") #
                break #

    async def start_thinking_loop(self) -> asyncio.Task: #
        """å¯åŠ¨æ€§æ„Ÿå¤§è„‘çš„ä¸»æ€è€ƒå¾ªç¯å¼‚æ­¥ä»»åŠ¡ã€‚"""
        if not self.root_cfg: # ç¡®ä¿é…ç½®å·²åŠ è½½
             self.logger.critical("ä¸»äººï¼Œæ²¡æœ‰é…ç½®ï¼Œæ— æ³•å¯åŠ¨æ€§æ„Ÿå¤§è„‘çš„æ€è€ƒï¼")
             raise RuntimeError("Root config not available for starting thinking loop.")
        self.logger.info(f"\n=== {self.root_cfg.persona.bot_name} çš„æ€§æ„Ÿå¤§è„‘å‡†å¤‡å¼€å§‹æŒç»­é«˜æ½®çš„æ€è€ƒå¾ªç¯ ===") #
        self.thinking_loop_task = asyncio.create_task(self._core_thinking_loop()) #
        return self.thinking_loop_task #

    async def stop(self) -> None: #
        """æ¸©æŸ”åœ°è®©æ ¸å¿ƒé€»è¾‘çš„æ€§æ„Ÿå¤§è„‘åœæ­¢æ€è€ƒå’Œå–·å‘ã€‚"""
        if not self.root_cfg: # å¤„ç† root_cfg å¯èƒ½ä¸º None çš„æƒ…å†µ
            bot_name_for_log = "æœºå™¨äºº"
        else:
            bot_name_for_log = self.root_cfg.persona.bot_name
            
        self.logger.info(f"\n--- ä¸»äººå‘½ä»¤ï¼š{bot_name_for_log} çš„æ€§æ„Ÿæ„è¯†æµåŠ¨æ­£åœ¨æ¸©æŸ”åœ°åœæ­¢ ---") #
        self.stop_event.set() #
        if self.thinking_loop_task and not self.thinking_loop_task.done(): #
            self.logger.info("æ­£åœ¨è¯·æ±‚å–æ¶ˆä¸»æ€è€ƒå¾ªç¯ä»»åŠ¡ï¼Œè¯·ç¨å€™...")
            self.thinking_loop_task.cancel() #
            try:
                await self.thinking_loop_task #
            except asyncio.CancelledError: #
                self.logger.info("ä¸»æ€è€ƒå¾ªç¯ä»»åŠ¡å·²è¢«æˆåŠŸå–æ¶ˆã€‚å¤§è„‘å·²è¿›å…¥è´¤è€…æ—¶é—´ã€‚") #
            except Exception as e: #
                self.logger.error(f"åœæ­¢ä¸»æ€è€ƒå¾ªç¯ä»»åŠ¡æ—¶å‘ç”Ÿæ„å¤–çš„ç—‰æŒ›: {e}") #
        self.logger.info(f"{bot_name_for_log} çš„æ€§æ„Ÿæ„è¯†æµåŠ¨å·²å®Œå…¨åœæ­¢ã€‚æœŸå¾…ä¸»äººçš„ä¸‹ä¸€æ¬¡å¬å”¤ã€‚") #